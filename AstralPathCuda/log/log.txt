[INFO 2023-05-02 10:13:20 ]核函数数:1
[INFO 2023-05-02 10:13:20 ]设备函数数:1
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global->     const int N = 1000;//global
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 17 ms int[] __device__d;//length:2->int d[2] =  {};//length:2
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms int[] __device__d_x;//length:N->int d_x[N] =  {};//length:N
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms reduce()(GLOBAL)->reduce()
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx;->        const int tid = threadIdx.x;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdxx;->        const int bid = blockIdx.x;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         final int n = tid;->        const int n = tid;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 3 ms         int[] __shared__s_y = {};//extern->extern __shared__ int __shared__s_y[];
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         if (n < N) {->        if (n < N) {
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 12 ms             __shared__s_y[tid] = ICuda.__ldg(__device__d_x[n]);->            __shared__s_y[tid] = __ldg(&d_x[n]);
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         }->        }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads();->        __syncthreads();
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1)->        for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         {->        {
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms             if (tid < offset)->            if (tid < offset)
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms             {->            {
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset];->                __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms             }->            }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads();->            __syncthreads();
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         }->        }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         int y = __shared__s_y[tid];->        int y = __shared__s_y[tid];
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1)->        for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         {->        {
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff", y, offset);->            y += __shfl_down_sync(0xffffffff, y, offset);
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         }->        }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         if (tid == 0)->        if (tid == 0)
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         {->        {
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d[0], y);->            atomicAdd(&d[0], y);
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         }->        }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms     }->    }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         int[] ha = new int[N];->        int ha[N] = {};
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         for(int x = 0; x < N ; ++x) {->        for(int x = 0; x < N ; ++x) {
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms             ha[x] = 1;->            ha[x] = 1;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         }->        }
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         ha[0] = ICuda.atoi(argv[1]);->        ha[0] = atoi(argv[1]);
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("d_x","ha",ICuda.sizeof("int")*N);->        cudaMemcpyToSymbol(d_x,ha,sizeof(int)*N);
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         final int block_size = 128;->        const int block_size = 128;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size;->        const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 1 ms         __global__reduce();//tags:<<<block_size,grid_size,128>>>->        reduce<<<block_size,grid_size,128>>>();//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         int device_id = 0;->        int device_id = 0;
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("ha","d",ICuda.sizeof("int")*2);->        cudaMemcpyFromSymbol(ha,d,sizeof(int)*2);
[INFO 2023-05-02 10:13:20 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%d\n",ha[0]);->        printf("c=%d\n",ha[0]);
[INFO 2023-05-02 10:16:21 ]-----------------------------
[INFO 2023-05-02 10:16:21 ]核函数数:1
[INFO 2023-05-02 10:16:21 ]设备函数数:1
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global->     const int N = 1000;//global
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 18 ms int[] __device__d_x;//length:N->int d_x[N] =  {};//length:N
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms int[] __device__d;//length:2->int d[2] =  {};//length:2
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms reduce()(GLOBAL)->reduce()
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx;->        const int tid = threadIdx.x;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 4 ms         final int bid = blockIdxx;->        const int bid = blockIdx.x;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         final int n = tid;->        const int n = tid;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         int[] __shared__s_y = {};//extern->extern __shared__ int __shared__s_y[];
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         if (n < N) {->        if (n < N) {
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 9 ms             __shared__s_y[tid] = ICuda.__ldg(__device__d_x[n]);->            __shared__s_y[tid] = __ldg(&d_x[n]);
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         }->        }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads();->        __syncthreads();
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1)->        for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         {->        {
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms             if (tid < offset)->            if (tid < offset)
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms             {->            {
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset];->                __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms             }->            }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads();->            __syncthreads();
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         }->        }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         int y = __shared__s_y[tid];->        int y = __shared__s_y[tid];
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1)->        for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         {->        {
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff", y, offset);->            y += __shfl_down_sync(0xffffffff, y, offset);
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         }->        }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         if (tid == 0)->        if (tid == 0)
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         {->        {
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d[0], y);->            atomicAdd(&d[0], y);
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         }->        }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms     }->    }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         int[] ha = new int[N];->        int ha[N] = {};
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         for(int x = 0; x < N ; ++x) {->        for(int x = 0; x < N ; ++x) {
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms             ha[x] = 1;->            ha[x] = 1;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         }->        }
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         ha[0] = ICuda.atoi(argv[1]);->        ha[0] = atoi(argv[1]);
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("d_x","ha",ICuda.sizeof("int")*N);->        cudaMemcpyToSymbol(d_x,ha,sizeof(int)*N);
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         final int block_size = 128;->        const int block_size = 128;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size;->        const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         __global__reduce();//tags:<<<block_size,grid_size,128>>>->        reduce<<<block_size,grid_size,128>>>();//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 1 ms ->
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         int device_id = 0;->        int device_id = 0;
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("ha","d",ICuda.sizeof("int")*2);->        cudaMemcpyFromSymbol(ha,d,sizeof(int)*2);
[INFO 2023-05-02 10:16:21 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%d\n",ha[0]);->        printf("c=%d\n",ha[0]);
[INFO 2023-05-02 10:17:16 ]-----------------------------
[INFO 2023-05-02 10:17:16 ]核函数数:1
[INFO 2023-05-02 10:17:16 ]设备函数数:1
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 21 ms int[] __device__d_x;//length:N -> int d_x[N] =  {};//length:N
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 2 ms int[] __device__d;//length:2 -> int d[2] =  {};//length:2
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms reduce()(GLOBAL) -> reduce()
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdxx; ->         const int bid = blockIdx.x;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         int[] __shared__s_y = {};//extern -> extern __shared__ int __shared__s_y[];
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         if (n < N) { ->         if (n < N) {
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 9 ms             __shared__s_y[tid] = ICuda.__ldg(__device__d_x[n]); ->             __shared__s_y[tid] = __ldg(&d_x[n]);
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         int y = __shared__s_y[tid]; ->         int y = __shared__s_y[tid];
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff", y, offset); ->             y += __shfl_down_sync(0xffffffff, y, offset);
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d[0], y); ->             atomicAdd(&d[0], y);
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         int[] ha = new int[N]; ->         int ha[N] = {};
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         for(int x = 0; x < N ; ++x) { ->         for(int x = 0; x < N ; ++x) {
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms             ha[x] = 1; ->             ha[x] = 1;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         ha[0] = ICuda.atoi(argv[1]); ->         ha[0] = atoi(argv[1]);
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("d_x","ha",ICuda.sizeof("int")*N); ->         cudaMemcpyToSymbol(d_x,ha,sizeof(int)*N);
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 1 ms         __global__reduce();//tags:<<<block_size,grid_size,128>>> ->         reduce<<<block_size,grid_size,128>>>();//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         int device_id = 0; ->         int device_id = 0;
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("ha","d",ICuda.sizeof("int")*2); ->         cudaMemcpyFromSymbol(ha,d,sizeof(int)*2);
[INFO 2023-05-02 10:17:16 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%d\n",ha[0]); ->         printf("c=%d\n",ha[0]);
[INFO 2023-05-13 08:24:16 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:24:16 ]核函数数:1
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 2 ms test(int[] $h,int[] $b)(GLOBAL) -> test(int *h,int *b)
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 6 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = malloc(M);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         int[] $h = {}; ->         int *h;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         __global__test($d_x1,$d_y1);//<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size>>>(d_x1,d_y1);//<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1);//<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size>>>(d_x1,d_y1);//<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:24:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[ERROR 2023-05-13 08:24:16 ]202305132024.cu

[INFO 2023-05-13 08:25:30 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:25:30 ]核函数数:1
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 2 ms test(int[] $h,int[] $b)(GLOBAL) -> test(int *h,int *b)
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 9 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = malloc(M);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         int[] $h = {}; ->         int *h;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         __global__test($d_x1,$d_y1);//<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size>>>(d_x1,d_y1);//<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1);//<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size>>>(d_x1,d_y1);//<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:25:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[ERROR 2023-05-13 08:25:30 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305132025.cu(18): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305132025.cu(19): warning #177-D: variable "h" was declared but never referenced

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202305132025.cu".
202305132025.cu

[INFO 2023-05-13 08:28:14 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:28:14 ]核函数数:1
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 2 ms test(int[] $h,int[] $b)(GLOBAL) -> test(int *h,int *b)
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 9 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = malloc(M);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 2 ms         __global__test($d_x1,$d_y1);//tags:<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size,0,stream_1>>>(d_x1,d_y1);//tags:<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1);//tags:<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size,0,stream_2>>>(d_x1,d_y1);//tags:<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:28:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[ERROR 2023-05-13 08:28:14 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305132028.cu(18): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202305132028.cu".
202305132028.cu

[INFO 2023-05-13 08:29:06 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:29:06 ]核函数数:1
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 2 ms test(int[] $h,int[] $b)(GLOBAL) -> test(int *h,int *b)
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 7 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms         int[] $h_x = (int[]) ICuda.malloc(M); ->         int *h_x = (int*) malloc(M);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         __global__test($d_x1,$d_y1);//tags:<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size,0,stream_1>>>(d_x1,d_y1);//tags:<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         __global__test($d_x1,$d_y1);//tags:<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size,0,stream_2>>>(d_x1,d_y1);//tags:<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:29:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[INFO 2023-05-13 08:30:20 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:30:20 ]核函数数:1
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms test(int[] $h,int[] $b,int x)(GLOBAL) -> test(int *h,int *b,int x)
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms         System.out.printf("流 %d - (%d,%d)\n",x,threadIdxx,threadIdxy); ->         printf("流 %d - (%d,%d)\n",x,threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 10 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         int[] $h_x = (int[]) ICuda.malloc(M); ->         int *h_x = (int*) malloc(M);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size,0,stream_1>>>(d_x1,d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size,0,stream_2>>>(d_x1,d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:30:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[INFO 2023-05-13 08:31:10 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:31:10 ]核函数数:1
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 4 ms test(int[] $h,int[] $b,int x)(GLOBAL) -> test(int *h,int *b,int x)
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         System.out.printf("Stream: %d - (%d,%d)\n",x,threadIdxx,threadIdxy); ->         printf("Stream: %d - (%d,%d)\n",x,threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 8 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         int[] $h_x = (int[]) ICuda.malloc(M); ->         int *h_x = (int*) malloc(M);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size,0,stream_1>>>(d_x1,d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size,0,stream_2>>>(d_x1,d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:31:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[INFO 2023-05-13 08:33:52 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:33:52 ]核函数数:1
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 3 ms test(float[] $h,float[] $b,int x)(GLOBAL) -> test(float *h,float *b,int x)
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("Stream: %d - (%f,%f)\n",x,threadIdxx,threadIdxy); ->         printf("Stream: %d - (%f,%f)\n",x,threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         $b[threadIdxx] = ICuda.sqrt($h[threadIdxx]); ->         b[threadIdx.x] = sqrt(h[threadIdx.x]);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 7 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 2 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("float")*N; ->         int M = sizeof(float)*N;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         float[] $h_x = (float[]) ICuda.malloc(M); ->         float *h_x = (float*) malloc(M);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms             $h_x[x] = (float) ((x + 1) * 999.0123); ->             h_x[x] = (float) ((x + 1) * 999.0123);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         float[] $d_x1 = {}; ->         float *d_x1;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         float[] $d_y1 = {}; ->         float *d_y1;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size,0,stream_1>>>(d_x1,d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         __global__test($d_x1,$d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size,0,stream_2>>>(d_x1,d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:33:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[INFO 2023-05-13 08:39:01 ]-------------------------新纪录--------------------------
[INFO 2023-05-13 08:39:01 ]核函数数:1
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 1 ms test(int[] $h,int[] $b,int x)(GLOBAL) -> test(int *h,int *b,int x)
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         System.out.printf("Stream: %d - (%d,%d)\n",x,threadIdxx,threadIdxy); ->         printf("Stream: %d - (%d,%d)\n",x,threadIdx.x,threadIdx.y);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         $b[threadIdxx] = $h[threadIdxx]; ->         b[threadIdx.x] = h[threadIdx.x];
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         cudaStream_t stream_1 = new cudaStream_t(); ->         cudaStream_t stream_1 ;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         cudaStream_t stream_2 = new cudaStream_t(); ->         cudaStream_t stream_2 ;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 6 ms         ICuda.cudaStreamCreate(stream_1); ->         cudaStreamCreate(&stream_1);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaStreamCreate(stream_2); ->         cudaStreamCreate(&stream_2);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 1 ms         int[] $h_x = (int[]) ICuda.malloc(M); ->         int *h_x = (int*) malloc(M);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMallocHost("d_x1",M); ->         cudaMallocHost((void **)&d_x1,M);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyAsync("d_x1","h_x",M,cudaMemcpyHostToDevice,stream_1); ->         cudaMemcpyAsync(d_x1,h_x,M,cudaMemcpyHostToDevice,stream_1);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyAsync("d_x1","h_x",M,cudaMemcpyHostToDevice,stream_2); ->         cudaMemcpyAsync(d_x1,h_x,M,cudaMemcpyHostToDevice,stream_2);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMallocHost("d_y1",M); ->         cudaMallocHost((void **)&d_y1,M);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         __global__test($d_x1,$d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>> ->         test<<<grid_size,block_size,0,stream_1>>>(d_x1,d_y1,0);//tags:<<<grid_size,block_size,0,stream_1>>>
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         __global__test($d_x1,$d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>> ->         test<<<grid_size,block_size,0,stream_2>>>(d_x1,d_y1,1);//tags:<<<grid_size,block_size,0,stream_2>>>
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamSynchronize(stream_1); ->         cudaStreamSynchronize(stream_1);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 2 ms         ICuda.cudaStreamSynchronize(stream_2); ->         cudaStreamSynchronize(stream_2);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_1); ->         cudaStreamDestroy(stream_1);
[INFO 2023-05-13 08:39:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaStreamDestroy(stream_2); ->         cudaStreamDestroy(stream_2);
[INFO 2023-05-20 10:06:01 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:06:01 ]核函数数:1
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 3 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 20 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdxx; ->         const int bid = blockIdx.x;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 11 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 2 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         if (n == 0) { ->         if (n == 0) {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double[] hx = new double[N];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double[] hy = new double[N];
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         int device_id = 0; ->         int device_id = 0;
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("hx","temp",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(hx,temp,sizeof(double)*2);
[INFO 2023-05-20 10:06:01 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%d\n",hx[0]); ->         printf("c=%d\n",hx[0]);
[ERROR 2023-05-20 10:06:01 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(14): warning #177-D: variable "bid" was declared but never referenced

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(77): error: expected an identifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(77): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(78): error: expected an identifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(78): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(80): error: identifier "hx" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(81): error: identifier "hy" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(83): error: identifier "hx" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(84): error: identifier "hy" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202305202206.cu(91): warning #177-D: variable "device_id" was declared but never referenced

8 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202305202206.cu".
202305202206.cu

[INFO 2023-05-20 10:07:51 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:07:51 ]核函数数:1
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 14 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 3 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdxx; ->         const int bid = blockIdx.x;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 9 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 2 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         if (n == 0) { ->         if (n == 0) {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 2 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         int device_id = 0; ->         int device_id = 0;
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("hx","temp",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(hx,temp,sizeof(double)*2);
[INFO 2023-05-20 10:07:51 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%d\n",hx[0]); ->         printf("c=%d\n",hx[0]);
[INFO 2023-05-20 10:08:37 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:08:37 ]核函数数:1
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 23 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 3 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 12 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 3 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         if (n == 0) { ->         if (n == 0) {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 2 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         int device_id = 0; ->         int device_id = 0;
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("hx","temp",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(hx,temp,sizeof(double)*2);
[INFO 2023-05-20 10:08:37 ](Java2Cuda)耗时: 1 ms         System.out.printf("c=%f\n",hx[0]); ->         printf("c=%f\n",hx[0]);
[INFO 2023-05-20 10:08:58 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:08:58 ]核函数数:1
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 19 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 11 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 3 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 9 ms         { ->         {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         if (n == 0) { ->         if (n == 0) {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("hx","temp",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(hx,temp,sizeof(double)*2);
[INFO 2023-05-20 10:08:58 ](Java2Cuda)耗时: 1 ms         System.out.printf("c=%f\n",hx[0]); ->         printf("c=%f\n",hx[0]);
[INFO 2023-05-20 10:10:37 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:10:37 ]核函数数:1
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 19 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 3 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 2 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 2 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 5 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 2 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 10 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 3 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         if (n == 0) { ->         if (n == 0) {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 2 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 2 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 2 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:10:37 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:11:25 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:11:25 ]核函数数:1
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 3 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 22 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 8 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         if (n == 0) { ->         if (n == 0) {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:11:25 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:12:07 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:12:07 ]核函数数:1
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 15 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 6 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 2 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 2 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:12:07 ](Java2Cuda)耗时: 1 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:13:10 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:13:10 ]核函数数:1
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 17 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 2 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 2 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 7 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             System.out.printf("xy= %f",__device__temp[4]); ->             printf("xy= %f",temp[4]);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:13:10 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:13:52 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:13:52 ]核函数数:1
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 9 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 2 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 2 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 6 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy= %f",dxy); ->         printf("xy= %f",dxy);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 1 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:13:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:15:42 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:15:42 ]核函数数:1
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 10 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 2 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 2 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 8 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 2 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy= %f",dxy); ->         printf("xy= %f",dxy);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:15:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:16:05 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:16:05 ]核函数数:1
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 14 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 10 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 2 ms         System.out.printf("xy= %f",dxy); ->         printf("xy= %f",dxy);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 1 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("1",0); ->         printf("1",0);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:16:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:16:53 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:16:53 ]核函数数:1
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 3 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 12 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 2 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 7 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:16:53 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:17:38 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:17:38 ]核函数数:1
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 12 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 7 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 2 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("0\n"); ->         printf("0\n");
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:17:38 ](Java2Cuda)耗时: 1 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:18:11 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:18:11 ]核函数数:1
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 6 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 42 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 3 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 9 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 3 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 31 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 4 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 46 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 6 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 5 ms             { ->             {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 3 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 5 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 6 ms         { ->         {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 1 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:18:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:18:57 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:18:57 ]核函数数:1
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 3 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 19 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 2 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         System.out.printf("10"); ->         printf("10");
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 13 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 4 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:18:57 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:19:17 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:19:17 ]核函数数:1
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 16 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 2 ms double[] __device__y2;//length:N -> double y2[N] =  {};//length:N
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms double[] __device__xy;//length:N -> double xy[N] =  {};//length:N
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms double[] __device__x2;//length:N -> double x2[N] =  {};//length:N
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 25 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("10"); ->         printf("10");
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 8 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         System.out.printf("20"); ->         printf("20");
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx; ->             hx[cx] = 1.000 * cx;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx; ->             hy[cx] = 2.000 * cx;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:19:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:20:13 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:20:13 ]核函数数:1
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 14 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 7 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         System.out.printf("20"); ->         printf("20");
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 2 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 2 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 2 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx + 1; ->             hx[cx] = 1.000 * cx + 1;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 2 ms             hy[cx] = 2.000 * cx + 2; ->             hy[cx] = 2.000 * cx + 2;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         __global__cor(N);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(N);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:20:13 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:20:40 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:20:40 ]核函数数:1
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 2 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 14 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 10 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         System.out.printf("20"); ->         printf("20");
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx + 1; ->             hx[cx] = 1.000 * cx + 1;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx + 2; ->             hy[cx] = 2.000 * cx + 2;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 2 ms         __global__cor(1000);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(1000);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:20:40 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:21:26 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:21:26 ]核函数数:1
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 11 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 9 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("20"); ->             printf("20");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("20"); ->             printf("20");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         System.out.printf("20"); ->         printf("20");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 2 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx + 1; ->             hx[cx] = 1.000 * cx + 1;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms             hy[cx] = 2.000 * cx + 2; ->             hy[cx] = 2.000 * cx + 2;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         __global__cor(1000);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(1000);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:21:26 ](Java2Cuda)耗时: 1 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:21:46 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:21:46 ]核函数数:1
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 16 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         final int n = tid; ->         const int n = tid;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             System.out.printf("20"); ->             printf("20");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 8 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             System.out.printf("30"); ->             printf("30");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 2 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         System.out.printf("20"); ->         printf("20");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 2 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx + 1; ->             hx[cx] = 1.000 * cx + 1;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx + 2; ->             hy[cx] = 2.000 * cx + 2;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         __global__cor(1000);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(1000);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 2 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:21:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-05-20 10:23:02 ]-------------------------新纪录--------------------------
[INFO 2023-05-20 10:23:02 ]核函数数:1
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms      final int N = 10000;//global ->      const int N = 10000;//global
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 16 ms double[] __device__temp;//length:10 -> double temp[10] =  {};//length:10
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms double[] __device__y;//length:N -> double y[N] =  {};//length:N
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 2 ms double[] __device__x;//length:N -> double x[N] =  {};//length:N
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms cor(int limit)(GLOBAL) -> cor(int limit)
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdxx; ->         const int tid = threadIdx.x;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         final int n = blockDimx * blockIdxx + threadIdxx; ->         const int n = blockDim.x * blockIdx.x + threadIdx.x;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double[] __shared__x = {};//extern -> extern __shared__ double __shared__x[];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 2 ms         double[] __shared__x2 = {};//extern -> extern __shared__ double __shared__x2[];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double[] __shared__y = {};//extern -> extern __shared__ double __shared__y[];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         double[] __shared__y2 = {};//extern -> extern __shared__ double __shared__y2[];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double[] __shared__xy = {};//extern -> extern __shared__ double __shared__xy[];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         if (n < limit) { ->         if (n < limit) {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             System.out.printf("20"); ->             printf("20");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 10 ms             __shared__x[tid] = ICuda.__ldg(__device__x[n]); ->             __shared__x[tid] = __ldg(&x[n]);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             __shared__y[tid] = ICuda.__ldg(__device__y[n]); ->             __shared__y[tid] = __ldg(&y[n]);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             System.out.printf("30"); ->             printf("30");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid]; ->             __shared__x2[tid] = __shared__x[tid] * __shared__x[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid]; ->             __shared__y2[tid] = __shared__y[tid] * __shared__y[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid]; ->             __shared__xy[tid] = __shared__x[tid] * __shared__y[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("20"); ->         printf("20");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDimx >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms                 __shared__x[tid] += __shared__x[tid + offset]; ->                 __shared__x[tid] += __shared__x[tid + offset];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms                 __shared__x2[tid] += __shared__x2[tid + offset]; ->                 __shared__x2[tid] += __shared__x2[tid + offset];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms                 __shared__y[tid] += __shared__y[tid + offset]; ->                 __shared__y[tid] += __shared__y[tid + offset];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms                 __shared__y2[tid] += __shared__y2[tid + offset]; ->                 __shared__y2[tid] += __shared__y2[tid + offset];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms                 __shared__xy[tid] += __shared__xy[tid + offset]; ->                 __shared__xy[tid] += __shared__xy[tid + offset];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         System.out.printf("0"); ->         printf("0");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double dx = __shared__x[tid]; ->         double dx = __shared__x[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         double dx2 = __shared__x2[tid]; ->         double dx2 = __shared__x2[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double dy = __shared__y[tid]; ->         double dy = __shared__y[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double dy2 = __shared__y2[tid]; ->         double dy2 = __shared__y2[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         double dxy = __shared__xy[tid]; ->         double dxy = __shared__xy[tid];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms             dx += ICuda.__shfl_down_sync("0xffffffff", dx, offset); ->             dx += __shfl_down_sync(0xffffffff, dx, offset);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms             dx2 += ICuda.__shfl_down_sync("0xffffffff", dx2, offset); ->             dx2 += __shfl_down_sync(0xffffffff, dx2, offset);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dy += ICuda.__shfl_down_sync("0xffffffff", dy, offset); ->             dy += __shfl_down_sync(0xffffffff, dy, offset);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dy2 += ICuda.__shfl_down_sync("0xffffffff", dy2, offset); ->             dy2 += __shfl_down_sync(0xffffffff, dy2, offset);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dxy += ICuda.__shfl_down_sync("0xffffffff", dxy, offset); ->             dxy += __shfl_down_sync(0xffffffff, dxy, offset);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("1"); ->         printf("1");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[0], dx); ->             atomicAdd(&temp[0], dx);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[1], dx2); ->             atomicAdd(&temp[1], dx2);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[2], dy); ->             atomicAdd(&temp[2], dy);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[3], dy2); ->             atomicAdd(&temp[3], dy2);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__temp[4], dxy); ->             atomicAdd(&temp[4], dxy);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("2\n"); ->         printf("2\n");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         if (n == 1) { ->         if (n == 1) {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             System.out.printf("1"); ->             printf("1");
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dx = __device__temp[0]; ->             dx = temp[0];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dx2 = __device__temp[1]; ->             dx2 = temp[1];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dy = __device__temp[2]; ->             dy = temp[2];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dy2 = __device__temp[3]; ->             dy2 = temp[3];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             dxy = __device__temp[4]; ->             dxy = temp[4];
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             double fenzi = dxy - ((dx * dy) / limit); ->             double fenzi = dxy - ((dx * dy) / limit);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             double fenmu = ICuda.sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit))); ->             double fenmu = sqrt((dx2 - (dx / limit)) * (dy2 - (dy / limit)));
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             __device__temp[5] = fenzi / fenmu; ->             temp[5] = fenzi / fenmu;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             System.out.printf("r: %f",fenzi / fenmu); ->             printf("r: %f",fenzi / fenmu);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         double[] hx = new double[N]; ->         double hx[N] = {};
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         double[] hy = new double[N]; ->         double hy[N] = {};
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         for(int cx = 0; cx < N ; ++cx) { ->         for(int cx = 0; cx < N ; ++cx) {
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             hx[cx] = 1.000 * cx + 1; ->             hx[cx] = 1.000 * cx + 1;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms             hy[cx] = 2.000 * cx + 2; ->             hy[cx] = 2.000 * cx + 2;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("x","hx",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(x,hx,sizeof(double)*N);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyToSymbol("y","hy",ICuda.sizeof("double")*N); ->         cudaMemcpyToSymbol(y,hy,sizeof(double)*N);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         __global__cor(1000);//tags:<<<block_size,grid_size,128>>> ->         cor<<<block_size,grid_size,128>>>(1000);//tags:<<<block_size,grid_size,128>>>
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 1 ms         double[] re = new double[10]; ->         double re[10] = {};
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("re","temp",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(re,temp,sizeof(double)*10);
[INFO 2023-05-20 10:23:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("c=%f\n",re[5]); ->         printf("c=%f\n",re[5]);
[INFO 2023-06-17 09:19:28 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:19:28 ]核函数数:1
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms sum(double d_x[], double d_y[])(GLOBAL) -> sum(double d_x[], double d_y[])
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 13 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         final int stride = blockDim.x * gridDim.x; ->         const int stride = blockDim.x * gridDim.x;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         for (int n = bid * blockDim.x + tid; n < N; n += stride) ->         for (int n = bid * blockDim.x + tid; n < N; n += stride)
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms             y += d_x[n]; ->             y += d_x[n];
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 2 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 2 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(d_y, y); ->             atomicAdd(&d_y, y);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms             $a[x] = 1.0; ->             a[x] = 1.0;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeofdouble)*N);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*2); ->         cudaMalloc((void **)&d_y,sizeofdouble)*2);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-06-17 09:19:28 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-06-17 09:19:28 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172119.cu(38): error: no instance of overloaded function "atomicAdd" matches the argument list
            argument types are: (double **, double)

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172119.cu(48): error: identifier "sizeofdouble" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172119.cu(48): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172119.cu(50): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172119.cu(52): error: identifier "grid_size" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172119.cu(52): error: identifier "block_size" is undefined

6 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306172119.cu".
202306172119.cu

[INFO 2023-06-17 09:20:34 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:20:34 ]核函数数:1
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms sum(double d_x[], double d_y[])(GLOBAL) -> sum(double d_x[], double d_y[])
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 13 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         final int stride = blockDim.x * gridDim.x; ->         const int stride = blockDim.x * gridDim.x;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         for (int n = bid * blockDim.x + tid; n < N; n += stride) ->         for (int n = bid * blockDim.x + tid; n < N; n += stride)
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms             y += d_x[n]; ->             y += d_x[n];
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 4 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 2 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 4 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(d_y, y); ->             atomicAdd(&d_y, y);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 2 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0; ->             a[x] = 1.0;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeofdouble)*N);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*2); ->         cudaMalloc((void **)&d_y,sizeofdouble)*2);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-06-17 09:20:34 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-06-17 09:20:34 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172120.cu(38): error: no instance of overloaded function "atomicAdd" matches the argument list
            argument types are: (double **, double)

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172120.cu(48): error: identifier "sizeofdouble" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172120.cu(48): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172120.cu(50): error: expected a ";"

4 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306172120.cu".
202306172120.cu

[INFO 2023-06-17 09:23:11 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:23:11 ]核函数数:1
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms sum(double d_x[], double d_y[])(GLOBAL) -> sum(double d_x[], double d_y[])
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 16 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         final int stride = blockDim.x * gridDim.x; ->         const int stride = blockDim.x * gridDim.x;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         for (int n = bid * blockDim.x + tid; n < N; n += stride) ->         for (int n = bid * blockDim.x + tid; n < N; n += stride)
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms             y += d_x[n]; ->             y += d_x[n];
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 2 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 4 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(d_y, y); ->             atomicAdd(&d_y, y);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 2 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0; ->             a[x] = 1.0;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*2); ->         cudaMalloc((void **)&d_y,sizeof(double)*2);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 3 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-06-17 09:23:11 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-06-17 09:23:11 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172123.cu(38): error: no instance of overloaded function "atomicAdd" matches the argument list
            argument types are: (double **, double)

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306172123.cu".
202306172123.cu

[INFO 2023-06-17 09:24:55 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:24:55 ]核函数数:1
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 14 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         final int stride = blockDim.x * gridDim.x; ->         const int stride = blockDim.x * gridDim.x;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         for (int n = bid * blockDim.x + tid; n < N; n += stride) ->         for (int n = bid * blockDim.x + tid; n < N; n += stride)
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms             y += d_x[n]; ->             y += d_x[n];
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 2 ms             { ->             {
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 3 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y, y); ->             atomicAdd(&d_y, y);
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 2 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0; ->             a[x] = 1.0;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:24:55 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-06-17 09:24:55 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306172124.cu(39): error: no instance of overloaded function "atomicAdd" matches the argument list
            argument types are: (double (*)[2], double)

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306172124.cu".
202306172124.cu

[INFO 2023-06-17 09:25:16 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:25:16 ]核函数数:1
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 16 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         final int stride = blockDim.x * gridDim.x; ->         const int stride = blockDim.x * gridDim.x;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         for (int n = bid * blockDim.x + tid; n < N; n += stride) ->         for (int n = bid * blockDim.x + tid; n < N; n += stride)
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms             y += d_x[n]; ->             y += d_x[n];
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 2 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 2 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0; ->             a[x] = 1.0;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:25:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:27:56 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:27:56 ]核函数数:1
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 34 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 14 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         final int stride = blockDim.x * gridDim.x; ->         const int stride = blockDim.x * gridDim.x;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         for (int n = bid * blockDim.x + tid; n < N; n += stride) ->         for (int n = bid * blockDim.x + tid; n < N; n += stride)
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms             y += d_x[n]; ->             y += d_x[n];
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 3 ms         } ->         }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms             { ->             {
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms             $a[x] = 1.0; ->             a[x] = 1.0;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-17 09:27:56 ](Java2Cuda)耗时: 2 ms         System.out.printf("%d",$b[0]); ->         printf("%d",b[0]);
[INFO 2023-06-17 09:29:47 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:29:47 ]核函数数:1
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 16 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 2 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-17 09:29:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("%d",$b[0]); ->         printf("%d",b[0]);
[INFO 2023-06-17 09:31:23 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:31:23 ]核函数数:1
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 14 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 5 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 2 ms         __shared__s_y[tid] = y; ->         __shared__s_y[tid] = y;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d",y); ->             printf("%d",y);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-17 09:31:23 ](Java2Cuda)耗时: 0 ms         System.out.printf("%d",$b[0]); ->         printf("%d",b[0]);
[INFO 2023-06-17 09:34:04 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:34:04 ]核函数数:1
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 14 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 6 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 2 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d",y); ->             printf("%d",y);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-17 09:34:04 ](Java2Cuda)耗时: 0 ms         System.out.printf("%d",$b[0]); ->         printf("%d",b[0]);
[INFO 2023-06-17 09:34:37 ]-------------------------新纪录--------------------------
[INFO 2023-06-17 09:34:37 ]核函数数:1
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 18 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 2 ms sum(double d_x[])(GLOBAL) -> sum(double d_x[])
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 3 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         double[] $a = (double[]) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double*) malloc(sizeof(double)*N);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         double[] $b = (double[]) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double*) malloc(sizeof(double)*2);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-17 09:34:37 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-21 11:14:47 ]-------------------------新纪录--------------------------
[INFO 2023-06-21 11:14:47 ]使用版本:v1.2023.0617.09
[INFO 2023-06-21 11:14:47 ]核函数数:1
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 6 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 38 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms sum(double[] d_x)(GLOBAL) -> sum(double[] d_x)
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 15 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 2 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 2 ms             } ->             }
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = malloc(sizeof(double)*N);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = malloc(sizeof(double)*2);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 2 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-21 11:14:47 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[ERROR 2023-06-21 11:14:47 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212314.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212314.cu(13): error: identifier "d_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212314.cu(38): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212314.cu(39): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

4 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306212314.cu".
202306212314.cu

[INFO 2023-06-21 11:18:13 ]-------------------------新纪录--------------------------
[INFO 2023-06-21 11:18:13 ]使用版本:v1.2023.0617.09
[INFO 2023-06-21 11:18:13 ]核函数数:1
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 22 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms sum(double[] d_x)(GLOBAL) -> sum(double[] d_x)
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 12 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 2 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = malloc(sizeof(double)*N);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = malloc(sizeof(double)*2);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-21 11:18:13 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[ERROR 2023-06-21 11:18:13 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212318.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212318.cu(13): error: identifier "d_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212318.cu(38): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212318.cu(39): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

4 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306212318.cu".
202306212318.cu

[INFO 2023-06-21 11:21:35 ]-------------------------新纪录--------------------------
[INFO 2023-06-21 11:21:35 ]使用版本:v1.2023.0617.09
[INFO 2023-06-21 11:21:35 ]核函数数:1
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 36 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms sum(double[] d_x)(GLOBAL) -> sum(double[] d_x)
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 17 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 2 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-21 11:21:35 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[ERROR 2023-06-21 11:21:35 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212321.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202306212321.cu(13): error: identifier "d_x" is undefined

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202306212321.cu".
202306212321.cu

[INFO 2023-06-21 11:22:58 ]-------------------------新纪录--------------------------
[INFO 2023-06-21 11:22:58 ]使用版本:v1.2023.0617.09
[INFO 2023-06-21 11:22:58 ]核函数数:1
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 21 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 2 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-21 11:22:58 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-22 08:16:11 ]-------------------------新纪录--------------------------
[INFO 2023-06-22 08:16:11 ]使用版本:v1.2023.0621.10
[INFO 2023-06-22 08:16:11 ]核函数数:1
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 4 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 17 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 8 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 3 ms         } ->         }
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-22 08:16:11 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-22 08:17:39 ]-------------------------新纪录--------------------------
[INFO 2023-06-22 08:17:39 ]使用版本:v1.2023.0621.10
[INFO 2023-06-22 08:17:39 ]核函数数:1
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 18 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 10 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 2 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-22 08:17:39 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-22 08:18:39 ]-------------------------新纪录--------------------------
[INFO 2023-06-22 08:18:39 ]使用版本:v1.2023.0621.10
[INFO 2023-06-22 08:18:39 ]核函数数:1
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 17 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 2 ms             } ->             }
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 2 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-22 08:18:39 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-22 08:19:26 ]-------------------------新纪录--------------------------
[INFO 2023-06-22 08:19:26 ]使用版本:v1.2023.0621.10
[INFO 2023-06-22 08:19:26 ]核函数数:1
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 20 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 10 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 2 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         double[] $d_x1 = {}; ->         double *d_x1;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("hello world"); ->             printf("hello world");
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:19:26 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-22 08:36:22 ]-------------------------新纪录--------------------------
[INFO 2023-06-22 08:36:22 ]使用版本:v1.2023.0621.10
[INFO 2023-06-22 08:36:22 ]核函数数:1
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 25 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 5 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 15 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 3 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 9 ms             { ->             {
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 3 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 8 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         double[] $a = (double []) ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         double[] $d_x1 = {}; ->         double *d_x1;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms             System.out.printf("hello world"); ->             printf("hello world");
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 08:36:22 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-06-22 12:01:04 ]-------------------------新纪录--------------------------
[INFO 2023-06-22 12:01:04 ]使用版本:v1.2023.0621.10
[INFO 2023-06-22 12:01:04 ]核函数数:1
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 25 ms double[] __device__d_y;//length:2 -> double d_y[2] =  {};//length:2
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_y[0], y); ->             atomicAdd(&d_y[0], y);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a =  (double *) malloc(sizeof(double)*N);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms         double[] $b = (double []) ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0; ->             a[x] = 11.0;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         double[] $d_x1 = {}; ->         double *d_x1;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms             System.out.printf("hello world"); ->             printf("hello world");
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-06-22 12:01:04 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-07-07 05:54:04 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 05:54:04 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 05:54:04 ]核函数数:1
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 21 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 4 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], y); ->             atomicAdd(&d_z[0], y);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",x); ->             printf("%f\n",x);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 3 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*2); ->         double *b = (double *) malloc(sizeof(double)*2);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0 + 2.0 * x; ->             a[x] = 11.0 + 2.0 * x;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms             $a2[x] = 11.0 + x; ->             a2[x] = 11.0 + x;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 2 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms             System.out.printf("hello world"); ->             printf("hello world");
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:54:04 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-07-07 05:57:20 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 05:57:20 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 05:57:20 ]核函数数:1
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 11 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",x); ->             printf("%f\n",x);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             System.out.printf("%f\n",y); ->             printf("%f\n",y);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms             $a[x] = 11.0 + 2.0 * x; ->             a[x] = 11.0 + 2.0 * x;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11.0 + 1.0 * x; ->             a2[x] = 11.0 + 1.0 * x;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_y",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_y,sizeof(double)*2);
[INFO 2023-07-07 05:57:20 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-07-07 05:59:03 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 05:59:03 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 05:59:03 ]核函数数:1
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 15 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 6 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.0 + 2.0 * x; ->             a[x] = 11.0 + 2.0 * x;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms             $a2[x] = 11.0 + 1.0 * x; ->             a2[x] = 11.0 + 1.0 * x;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*2); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*2);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 2 ms         System.out.printf("%f",$b[0]); ->         printf("%f",b[0]);
[INFO 2023-07-07 05:59:03 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f",$b[1]); ->         printf("%f",b[1]);
[INFO 2023-07-07 05:59:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 05:59:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 05:59:29 ]核函数数:1
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 17 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 2 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms             $a[x] = 11.0 + 2.0 * x; ->             a[x] = 11.0 + 2.0 * x;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11.0 + 1.0 * x; ->             a2[x] = 11.0 + 1.0 * x;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 05:59:29 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[INFO 2023-07-07 06:00:20 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 06:00:20 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 06:00:20 ]核函数数:1
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 25 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 12 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 2 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms             $a[x] = 11.0 + (2.0 * x); ->             a[x] = 11.0 + (2.0 * x);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11.0 + (1.0 * x); ->             a2[x] = 11.0 + (1.0 * x);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 2 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 06:00:20 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[INFO 2023-07-07 06:00:48 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 06:00:48 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 06:00:48 ]核函数数:1
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 14 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 4 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms             $a[x] = 11.123; ->             a[x] = 11.123;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11.123; ->             a2[x] = 11.123;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 06:00:48 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[INFO 2023-07-07 06:01:19 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 06:01:19 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 06:01:19 ]核函数数:1
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 15 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 2 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 06:01:19 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[INFO 2023-07-07 06:51:39 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 06:51:39 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 06:51:39 ]核函数数:1
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 15 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 6 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y2 = {};//length:128 -> __shared__ double __shared__s_y2[128];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         double y2 = 0.0; ->         double y2 = 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 2 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0; ->         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; ->         for (int offset = blockDim.x >> 1;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 2 ms  offset >= 32; ->  offset >= 32;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms  offset >>= 1); ->  offset >>= 1);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms                 __shared__s_y2[tid] += __shared__s_y2[tid + offset]; ->                 __shared__s_y2[tid] += __shared__s_y2[tid + offset];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         y2= __shared__s_y2[tid]; ->         y2= __shared__s_y2[tid];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; ->         for (int offset = 16;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  offset > 0; ->  offset > 0;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  offset >>= 1); ->  offset >>= 1);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             y2 += ICuda.__shfl_down_sync("0xffffffff",y2, offset); ->             y2 += __shfl_down_sync(0xffffffff,y2, offset);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], y2); ->             atomicAdd(&d_z[3], y2);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[4], xy); ->             atomicAdd(&d_z[4], xy);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ; ->         for (int x = 0 ;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms x < N; -> x < N;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms x ++) {; -> x ++) {;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 1 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 06:51:39 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[ERROR 2023-07-07 06:51:39 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071851.cu(32): error: identifier "offset" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071851.cu(52): error: identifier "offset" is undefined

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307071851.cu".
202307071851.cu

[INFO 2023-07-07 06:55:38 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 06:55:38 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 06:55:38 ]核函数数:1
[INFO 2023-07-07 06:55:38 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 06:55:38 ](Java2Cuda)耗时: 16 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 06:55:38 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[ERROR 2023-07-07 06:55:38 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071855.cu(8): error: expected a ";"

At end of source: error: expected a "}"
D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071855.cu(7): note #3196-D: to match this "{"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071855.cu(4): warning #177-D: variable "N" was declared but never referenced

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307071855.cu".
202307071855.cu

[INFO 2023-07-07 06:58:47 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 06:58:47 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 06:58:47 ]核函数数:1
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 4 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 14 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 06:58:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[ERROR 2023-07-07 06:58:47 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071858.cu(8): error: expected a ";"

At end of source: error: expected a "}"
D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071858.cu(7): note #3196-D: to match this "{"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307071858.cu(4): warning #177-D: variable "N" was declared but never referenced

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307071858.cu".
202307071858.cu

[INFO 2023-07-07 07:00:15 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:00:15 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:00:15 ]核函数数:1
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 26 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 12 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y2 = {};//length:128 -> __shared__ double __shared__s_y2[128];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double y2 = 0.0; ->         double y2 = 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0; ->         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms                 __shared__s_y2[tid] += __shared__s_y2[tid + offset]; ->                 __shared__s_y2[tid] += __shared__s_y2[tid + offset];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         y2= __shared__s_y2[tid]; ->         y2= __shared__s_y2[tid];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 5 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             y2 += ICuda.__shfl_down_sync("0xffffffff",y2, offset); ->             y2 += __shfl_down_sync(0xffffffff,y2, offset);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 5 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 3 ms         } ->         }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 3 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], y2); ->             atomicAdd(&d_z[3], y2);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[4], xy); ->             atomicAdd(&d_z[4], xy);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 4 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 5 ms     } ->     }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 5 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 2 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:00:15 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \ns",$b[1]); ->         printf("%f \ns",b[1]);
[INFO 2023-07-07 07:00:56 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:00:56 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:00:56 ]核函数数:1
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 10 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y2 = {};//length:128 -> __shared__ double __shared__s_y2[128];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 2 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         double y2 = 0.0; ->         double y2 = 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0; ->         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms                 __shared__s_y2[tid] += __shared__s_y2[tid + offset]; ->                 __shared__s_y2[tid] += __shared__s_y2[tid + offset];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         y2= __shared__s_y2[tid]; ->         y2= __shared__s_y2[tid];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms             y2 += ICuda.__shfl_down_sync("0xffffffff",y2, offset); ->             y2 += __shfl_down_sync(0xffffffff,y2, offset);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], y2); ->             atomicAdd(&d_z[3], y2);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[4], xy); ->             atomicAdd(&d_z[4], xy);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:00:56 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:04:16 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:04:16 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:04:16 ]核函数数:1
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 18 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y2 = {};//length:128 -> __shared__ double __shared__s_y2[128];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         double y2 = 0.0; ->         double y2 = 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0; ->         __shared__s_y2[tid] = (n < N) ? (__shared__s_y[tid] * __shared__s_y[tid]) : 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms                 __shared__s_y2[tid] += __shared__s_y2[tid + offset]; ->                 __shared__s_y2[tid] += __shared__s_y2[tid + offset];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         y2= __shared__s_y2[tid]; ->         y2= __shared__s_y2[tid];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             y2 += ICuda.__shfl_down_sync("0xffffffff",y2, offset); ->             y2 += __shfl_down_sync(0xffffffff,y2, offset);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], y2); ->             atomicAdd(&d_z[3], y2);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[4], xy); ->             atomicAdd(&d_z[4], xy);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:04:16 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:09:47 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:09:47 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:09:47 ]核函数数:1
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 21 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 8 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 2 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             $a[x] = 1.0 * x; ->             a[x] = 1.0 * x;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms             $a2[x] = 2.0 * x; ->             a2[x] = 2.0 * x;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:09:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:10:11 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:10:11 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:10:11 ]核函数数:1
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 17 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 8 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 2 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11 + 2.0 * x; ->             a2[x] = 11 + 2.0 * x;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:10:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:11:46 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:11:46 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:11:46 ]核函数数:1
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 12 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 8 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 2 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11 + 3.0 * x; ->             a2[x] = 11 + 3.0 * x;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:11:46 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:12:45 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:12:45 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:12:45 ]核函数数:1
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 14 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 6 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11 + 3.0124 * x; ->             a2[x] = 11 + 3.0124 * x;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 5 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:12:45 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:21:31 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:21:31 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:21:31 ]核函数数:1
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 15 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 4 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 7 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 2 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 2 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11 + 3.0124 * x; ->             a2[x] = 11 + 3.0124 * x;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[0]); ->         printf("%f \n",b[0]);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[1]); ->         printf("%f \n",b[1]);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f \n",$b[2]); ->         printf("%f \n",b[2]);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[3]); ->         printf("%f \n",b[3]);
[INFO 2023-07-07 07:21:31 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f \n",$b[4]); ->         printf("%f \n",b[4]);
[INFO 2023-07-07 07:25:03 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:25:03 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:25:03 ]核函数数:1
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 4 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 28 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 13 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 2 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 2 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms             $a2[x] = 11 + 3.0124 * x; ->             a2[x] = 11 + 3.0124 * x;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         System.out.printf("x的和:  %f \n",$b[0]); ->         printf("x的和:  %f \n",b[0]);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         System.out.printf("y的和: %f \n",$b[1]); ->         printf("y的和: %f \n",b[1]);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2的和: %f \n",$b[2]); ->         printf("x2的和: %f \n",b[2]);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy的和: %f \n",$b[3]); ->         printf("xy的和: %f \n",b[3]);
[INFO 2023-07-07 07:25:03 ](Java2Cuda)耗时: 1 ms         System.out.printf("结果: y =  %f * x + %f \n",$b[4],$b[5]); ->         printf("结果: y =  %f * x + %f \n",b[4],b[5]);
[INFO 2023-07-07 07:26:18 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:26:18 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:26:18 ]核函数数:1
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 12 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 8 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 2 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:26:18 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*[INFO 2023-07-07 07:26:30 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:26:30 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:26:30 ]核函数数:1
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 3 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 20 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 4 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms             } ->             }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms             $a2[x] = 11 + 3.0124 * x; ->             a2[x] = 11 + 3.0124 * x;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-07 07:26:30 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-07 07:27:44 ]-------------------------新纪录--------------------------
[INFO 2023-07-07 07:27:44 ]使用版本:v1.2023.0621.10
[INFO 2023-07-07 07:27:44 ]核函数数:1
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 10 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 15 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 4 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 3 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11 + 3.0 * x; ->             a2[x] = 11 + 3.0 * x;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 7 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 2 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-07 07:27:44 ](Java2Cuda)耗时: 1 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-09 09:12:07 ]-------------------------新纪录--------------------------
[INFO 2023-07-09 09:12:07 ]使用版本:v1.2023.0621.10
[INFO 2023-07-09 09:12:07 ]核函数数:1
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 22 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x;final int bid = blockIdx.x; ->         const int tid = threadIdx.x;const int bid = blockIdx.x;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 10 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 2 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms             $a2[x] = 11 + 3.0 * x; ->             a2[x] = 11 + 3.0 * x;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-09 09:12:07 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-09 09:34:38 ]-------------------------新纪录--------------------------
[INFO 2023-07-09 09:34:38 ]使用版本:v1.2023.0621.10
[INFO 2023-07-09 09:34:38 ]核函数数:1
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 2 ms      final int N = 5;//global ->      const int N = 5;//global
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 27 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 4 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 13 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 3 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 2 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             $a[x] = 11 + 1.0 * x; ->             a[x] = 11 + 1.0 * x;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms             $a2[x] = 11 + 3.0 * x; ->             a2[x] = 11 + 3.0 * x;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-09 09:34:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-09 09:35:52 ]-------------------------新纪录--------------------------
[INFO 2023-07-09 09:35:52 ]使用版本:v1.2023.0621.10
[INFO 2023-07-09 09:35:52 ]核函数数:1
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms      final int N = 100000;//global ->      const int N = 100000;//global
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 37 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 13 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 47 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 7 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 4 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 3 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 3 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 1 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-09 09:35:52 ](Java2Cuda)耗时: 4 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-09 09:37:02 ]-------------------------新纪录--------------------------
[INFO 2023-07-09 09:37:02 ]使用版本:v1.2023.0621.10
[INFO 2023-07-09 09:37:02 ]核函数数:1
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 2 ms      final int N = 10000000;//global ->      const int N = 10000000;//global
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 28 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 5 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 1 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 2 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-09 09:37:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-09 09:38:42 ]-------------------------新纪录--------------------------
[INFO 2023-07-09 09:38:42 ]使用版本:v1.2023.0621.10
[INFO 2023-07-09 09:38:42 ]核函数数:1
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 2 ms      final int N = 1000000000;//global ->      const int N = 1000000000;//global
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 25 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 5 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 13 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 4 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 3 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-09 09:38:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-09 09:39:32 ]-------------------------新纪录--------------------------
[INFO 2023-07-09 09:39:32 ]使用版本:v1.2023.0621.10
[INFO 2023-07-09 09:39:32 ]核函数数:1
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 2 ms      final int N = 100000000;//global ->      const int N = 100000000;//global
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 19 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 8 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 2 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 2 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-09 09:39:32 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-10 08:42:21 ]-------------------------新纪录--------------------------
[INFO 2023-07-10 08:42:21 ]使用版本:v1.2023.0621.10
[INFO 2023-07-10 08:42:21 ]核函数数:1
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 4 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 8 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-10 08:42:21 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-12 10:21:52 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:21:52 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:21:52 ]使用cuRAND库
[INFO 2023-07-12 10:21:52 ]核函数数:1
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 20 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 0 ms connect()(GLOBAL) -> connect()
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 8 ms  -> 
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 2 ms     } ->     }
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 19 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 73 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 9 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 4 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 5 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 2 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 13 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("int") * N); ->         cudaMalloc((void **)&g_health, sizeof(int) * N);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 3 ms         ICuda.curandGenerateUniformDouble(generator, $g_health, N); ->         curandGenerateUniformDouble(generator, g_health, N);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 2 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 25 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("int") * N); ->         cudaMalloc((void **)&g_attract, sizeof(int) * N);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 9 ms         ICuda.curandGenerateUniformDouble(generator, $g_attract, N); ->         curandGenerateUniformDouble(generator, g_attract, N);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 2 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 123456); ->         curandSetPseudoRandomGeneratorSeed(generator, 123456);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("int") * N); ->         cudaMalloc((void **)&g_point, sizeof(int) * N);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 4 ms         ICuda.curandGenerateUniformDouble(generator, $g_point, N); ->         curandGenerateUniformDouble(generator, g_point, N);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 5 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:21:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:25:12 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:25:12 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:25:12 ]使用cuRAND库
[INFO 2023-07-12 10:25:12 ]核函数数:1
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 2 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms connect(int[] health)(GLOBAL) -> connect(int[] health)
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         System.out.printf("%d\n",health[n]); ->         printf("%d\n",health[n]);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 10 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 3 ms         int[] $g_health = {}; ->         int *g_health;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         int[] $g_attract = {}; ->         int *g_attract;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         int[] $g_point = {}; ->         int *g_point;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("int") * N); ->         cudaMalloc((void **)&g_health, sizeof(int) * N);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateUniformDouble(generator, $g_health, N); ->         curandGenerateUniformDouble(generator, g_health, N);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("int") * N); ->         cudaMalloc((void **)&g_attract, sizeof(int) * N);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_attract, N); ->         curandGenerateUniformDouble(generator, g_attract, N);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 123456); ->         curandSetPseudoRandomGeneratorSeed(generator, 123456);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("int") * N); ->         cudaMalloc((void **)&g_point, sizeof(int) * N);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_point, N); ->         curandGenerateUniformDouble(generator, g_point, N);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         __global__connect($g_health); ->         connect<<<grid_size,block_size>>>(g_health);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:25:12 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:25:12 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122225.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122225.cu(11): error: identifier "health" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122225.cu(22): error: argument of type "int *" is incompatible with parameter of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122225.cu(25): error: argument of type "int *" is incompatible with parameter of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122225.cu(28): error: argument of type "int *" is incompatible with parameter of type "double *"

5 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122225.cu".
202307122225.cu

[INFO 2023-07-12 10:26:41 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:26:41 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:26:41 ]使用cuRAND库
[INFO 2023-07-12 10:26:41 ]核函数数:1
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 3 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms connect(Double[] health)(GLOBAL) -> connect(Double[] health)
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         System.out.printf("%f\n",health[n]); ->         printf("%f\n",health[n]);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 13 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 3 ms         Double[] $g_health = {}; ->         Double *g_health;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         Double[] $g_attract = {}; ->         Double *g_attract;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         Double[] $g_point = {}; ->         Double *g_point;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 3 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("Double") * N); ->         cudaMalloc((void **)&g_health, sizeof(Double) * N);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 4 ms         ICuda.curandGenerateUniformDouble(generator, $g_health, N); ->         curandGenerateUniformDouble(generator, g_health, N);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("Double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(Double) * N);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_attract, N); ->         curandGenerateUniformDouble(generator, g_attract, N);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 123456); ->         curandSetPseudoRandomGeneratorSeed(generator, 123456);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("Double") * N); ->         cudaMalloc((void **)&g_point, sizeof(Double) * N);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateUniformDouble(generator, $g_point, N); ->         curandGenerateUniformDouble(generator, g_point, N);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health); ->         connect<<<grid_size,block_size>>>(g_health);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:26:41 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:26:41 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(7): error: attribute "__global__" does not apply here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(7): error: incomplete type is not allowed

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(7): error: identifier "Double" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(7): error: expected an expression

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(7): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(35): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(37): error: expected a declaration

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122226.cu(5): warning #177-D: variable "N" was declared but never referenced

7 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122226.cu".
202307122226.cu

[INFO 2023-07-12 10:27:17 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:27:17 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:27:17 ]使用cuRAND库
[INFO 2023-07-12 10:27:17 ]核函数数:1
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms connect(double[] health)(GLOBAL) -> connect(double[] health)
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 2 ms         System.out.printf("%f\n",health[n]); ->         printf("%f\n",health[n]);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 10 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 2 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateUniformDouble(generator, $g_health, N); ->         curandGenerateUniformDouble(generator, g_health, N);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 3 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_attract, N); ->         curandGenerateUniformDouble(generator, g_attract, N);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 123456); ->         curandSetPseudoRandomGeneratorSeed(generator, 123456);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_point, N); ->         curandGenerateUniformDouble(generator, g_point, N);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health); ->         connect<<<grid_size,block_size>>>(g_health);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:27:17 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:27:17 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122227.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122227.cu(11): error: identifier "health" is undefined

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122227.cu".
202307122227.cu

[INFO 2023-07-12 10:27:52 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:27:52 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:27:52 ]使用cuRAND库
[INFO 2023-07-12 10:27:52 ]核函数数:1
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 5 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 4 ms connect(double[] $health)(GLOBAL) -> connect(double *health)
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         System.out.printf("%f\n",$health[n]); ->         printf("%f\n",health[n]);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 11 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateUniformDouble(generator, $g_health, N); ->         curandGenerateUniformDouble(generator, g_health, N);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_attract, N); ->         curandGenerateUniformDouble(generator, g_attract, N);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 123456); ->         curandSetPseudoRandomGeneratorSeed(generator, 123456);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateUniformDouble(generator, $g_point, N); ->         curandGenerateUniformDouble(generator, g_point, N);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 3 ms         __global__connect($g_health); ->         connect<<<grid_size,block_size>>>(g_health);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:27:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:29:44 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:29:44 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:29:44 ]使用cuRAND库
[INFO 2023-07-12 10:29:44 ]核函数数:1
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 4 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 6 ms connect(double[] $health)(GLOBAL) -> connect(double *health)
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 6 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         System.out.printf("%f\n",$health[n]); ->         printf("%f\n",health[n]);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 21 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 3 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 6 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 123456); ->         curandSetPseudoRandomGeneratorSeed(generator, 123456);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         ICuda.curandGenerateNormalDouble(generator, $g_point, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_point, N,100.0,20.0);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health); ->         connect<<<grid_size,block_size>>>(g_health);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 2 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:29:44 ](Java2Cuda)耗时: 7 ms  -> 
[INFO 2023-07-12 10:33:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:33:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:33:29 ]使用cuRAND库
[INFO 2023-07-12 10:33:29 ]核函数数:1
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 3 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double health,double attract,double
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 10 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 2 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 3 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:33:29 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-07-12 10:33:29 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(11): error: expression must have pointer-to-object type but it has type "double"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(11): error: expression must have pointer-to-object type but it has type "double"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(11): error: identifier "point" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(30): error: argument of type "double *" is incompatible with parameter of type "double"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(30): error: argument of type "double *" is incompatible with parameter of type "double"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122233.cu(30): error: argument of type "double *" is incompatible with parameter of type "double"

7 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122233.cu".
202307122233.cu

[INFO 2023-07-12 10:34:49 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:34:49 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:34:49 ]使用cuRAND库
[INFO 2023-07-12 10:34:49 ]核函数数:1
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 3 ms connect(double[] $health)(GLOBAL) -> connect(double *health)
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%f)\n",$health[n]); ->         printf("(%f)\n",health[n]);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 9 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 3 ms         __global__connect($g_health); ->         connect<<<grid_size,block_size>>>(g_health);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:34:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:40:06 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:40:06 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:40:06 ]使用cuRAND库
[INFO 2023-07-12 10:40:06 ]核函数数:1
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 2 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 3 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *health,double[] *attract,double[] *point)
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 9 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 2 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 4 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 2 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:40:06 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-07-12 10:40:06 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122240.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122240.cu(11): error: identifier "attract" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122240.cu(11): error: identifier "point" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122240.cu(30): error: too many arguments in function call

4 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122240.cu".
202307122240.cu

[INFO 2023-07-12 10:41:15 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:41:15 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:41:15 ]使用cuRAND库
[INFO 2023-07-12 10:41:15 ]核函数数:1
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *health,double* *attract,double* *point)
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 4 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:41:15 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:41:15 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122241.cu(11): warning #181-D: argument is incompatible with corresponding format string conversion

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122241.cu(11): warning #181-D: argument is incompatible with corresponding format string conversion

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122241.cu(30): error: argument of type "double *" is incompatible with parameter of type "double **"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122241.cu(30): error: argument of type "double *" is incompatible with parameter of type "double **"

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122241.cu".
202307122241.cu

[INFO 2023-07-12 10:42:45 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:42:45 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:42:45 ]使用cuRAND库
[INFO 2023-07-12 10:42:45 ]核函数数:1
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 2 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *healthdouble[] *attractdouble[] *point)
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 5 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 2 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:42:45 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:42:45 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122242.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122242.cu(11): error: identifier "health" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122242.cu(11): error: identifier "attract" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122242.cu(11): error: identifier "point" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122242.cu(30): error: argument of type "double *" is incompatible with parameter of type "double **"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122242.cu(30): error: too many arguments in function call

6 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122242.cu".
202307122242.cu

[INFO 2023-07-12 10:44:47 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:44:47 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:44:47 ]使用cuRAND库
[INFO 2023-07-12 10:44:47 ]核函数数:1
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 2 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 3 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *health,double[] *attract,double[] *point)
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 2 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 12 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 2 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:44:47 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:44:47 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122244.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122244.cu(11): error: identifier "attract" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122244.cu(11): error: identifier "point" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122244.cu(30): error: too many arguments in function call

4 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122244.cu".
202307122244.cu

[INFO 2023-07-12 10:45:56 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:45:56 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:45:56 ]使用cuRAND库
[INFO 2023-07-12 10:45:56 ]核函数数:1
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 2 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 4 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *healthdouble *attract,double[] *point)
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 12 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 3 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:45:56 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:45:56 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122245.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122245.cu(11): error: identifier "health" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122245.cu(11): error: identifier "attract" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122245.cu(11): error: identifier "point" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122245.cu(30): error: too many arguments in function call

5 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122245.cu".
202307122245.cu

[INFO 2023-07-12 10:46:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:46:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:46:29 ]使用cuRAND库
[INFO 2023-07-12 10:46:29 ]核函数数:1
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 2 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *health,double *attract,double[] *point)
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 6 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:46:29 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-12 10:46:29 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122246.cu(7): error: expected a ")"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122246.cu(11): error: identifier "point" is undefined

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122246.cu".
202307122246.cu

[INFO 2023-07-12 10:47:50 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:47:50 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:47:50 ]使用cuRAND库
[INFO 2023-07-12 10:47:50 ]核函数数:1
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 2 ms      final int N = 762;//global ->      const int N = 762;//global
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 2 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *health,double *attract,double *point)
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 4 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:49:00 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:49:00 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:49:00 ]使用cuRAND库
[INFO 2023-07-12 10:49:00 ]核函数数:1
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 2 ms      final int N = 640;//global ->      const int N = 640;//global
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 3 ms connect(double[] $health,double[] $attract,double[] $point)(GLOBAL) -> connect(double *health,double *attract,double *point)
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%f,%f,%f)\n",$health[n],$attract[n],$point[n]); ->         printf("(%f,%f,%f)\n",health[n],attract[n],point[n]);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         curandGenerator_t generator = new curandGenerator_t(); ->         curandGenerator_t generator ;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 6 ms         ICuda.curandCreateGenerator(generator, CURAND_RNG_QUASI_SOBOL32); ->         curandCreateGenerator(&generator, CURAND_RNG_QUASI_SOBOL32);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         double[] $g_health = {}; ->         double *g_health;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         double[] $g_attract = {}; ->         double *g_attract;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         double[] $g_point = {}; ->         double *g_point;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 1234); ->         curandSetPseudoRandomGeneratorSeed(generator, 1234);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc($g_health, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_health, sizeof(double) * N);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         ICuda.curandGenerateNormalDouble(generator, $g_health, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_health, N,100.0,20.0);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         ICuda.curandSetPseudoRandomGeneratorSeed(generator, 12345); ->         curandSetPseudoRandomGeneratorSeed(generator, 12345);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_attract, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_attract, sizeof(double) * N);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 3 ms         ICuda.curandGenerateNormalDouble(generator, $g_attract, N,100.0,20.0); ->         curandGenerateNormalDouble(generator, g_attract, N,100.0,20.0);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc($g_point, ICuda.sizeof("double") * N); ->         cudaMalloc((void **)&g_point, sizeof(double) * N);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms         __global__connect($g_health,$g_attract,$g_point); ->         connect<<<grid_size,block_size>>>(g_health,g_attract,g_point);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($g_health); ->         cudaFree(g_health);
[INFO 2023-07-12 10:49:00 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:51:36 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:51:36 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:51:36 ]核函数数:1
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 9 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 5 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-12 10:51:36 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 10:52:24 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:52:24 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:52:24 ]核函数数:1
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 4 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 16 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms sum(double[] $d_x)(GLOBAL) -> sum(double *d_x)
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 2 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 2 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 2 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 10:52:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 10:57:03 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 10:57:03 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 10:57:03 ]核函数数:1
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 2 ms      final int N = argc;//global ->      const int N = argc;//global
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 14 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x)(GLOBAL) -> sum(int *d_x)
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 7 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 2 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         int[] $a = ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = malloc(sizeof(int)*N);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 10:57:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 10:57:03 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122257.cu(4): error: identifier "argc" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122257.cu(36): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122257.cu".
202307122257.cu

[INFO 2023-07-12 11:17:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:17:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:17:29 ]核函数数:1
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 4 ms      final int N = argc;//global ->      const int N = argc;//global
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 15 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 3 ms sum(int[] $d_x)(GLOBAL) -> sum(int *d_x)
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         int[] $a = ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = malloc(sizeof(int)*N);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 2 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:17:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:17:29 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122317.cu(4): error: identifier "argc" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122317.cu(36): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122317.cu".
202307122317.cu

[INFO 2023-07-12 11:18:36 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:18:36 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:18:36 ]核函数数:1
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 14 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 3 ms sum(int[] $d_x)(GLOBAL) -> sum(int *d_x)
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 9 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         int[] $a = ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = malloc(sizeof(int)*N);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:18:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:18:36 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122318.cu(13): warning #20094-D: a host variable "N" cannot be directly read in a device function

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122318.cu(36): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122318.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122318.cu".
202307122318.cu

[INFO 2023-07-12 11:21:23 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:21:23 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:21:23 ]核函数数:1
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 17 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x)(GLOBAL) -> sum(int *d_x)
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 7 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         int[] $a = ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = malloc(sizeof(int)*N);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 2 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:21:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:21:23 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122321.cu(13): warning #20094-D: a host variable "N" cannot be directly read in a device function

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122321.cu(36): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122321.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

2 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122321.cu".
202307122321.cu

[INFO 2023-07-12 11:22:52 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:22:52 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:22:52 ]核函数数:1
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 15 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x)(GLOBAL) -> sum(int *d_x)
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 2 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 2 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x); ->         sum<<<grid_size,block_size>>>(d_x);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:22:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:22:52 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122322.cu(13): warning #20094-D: a host variable "N" cannot be directly read in a device function

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122322.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122322.cu".
202307122322.cu

[INFO 2023-07-12 11:25:03 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:25:03 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:25:03 ]核函数数:1
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 13 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 9 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 2 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 2 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:25:03 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:25:03 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122325.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122325.cu".
202307122325.cu

[INFO 2023-07-12 11:25:22 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:25:22 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:25:22 ]核函数数:1
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 12 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 2 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 2 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:25:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:25:22 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122325.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122325.cu".
202307122325.cu

[INFO 2023-07-12 11:25:40 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:25:40 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:25:40 ]核函数数:1
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 15 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 4 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 9 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 2 ms             } ->             }
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 2 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 17 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:25:40 ](Java2Cuda)耗时: 2 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:25:40 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122325.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122325.cu".
202307122325.cu

[INFO 2023-07-12 11:26:47 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:26:47 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:26:47 ]核函数数:1
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 12 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 5 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 2 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = malloc(sizeof(int)*10);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 2 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:26:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[ERROR 2023-07-12 11:26:47 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122326.cu(37): error: a value of type "void *" cannot be used to initialize an entity of type "int *"

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122326.cu".
202307122326.cu

[INFO 2023-07-12 11:28:27 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:28:27 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:28:27 ]核函数数:1
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 20 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 2 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 2 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 2 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 3 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = malloc(sizeof(double)*N);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = malloc(sizeof(double)*N);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = malloc(sizeof(double)*10);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-12 11:28:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[ERROR 2023-07-12 11:28:27 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122328.cu(67): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122328.cu(68): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122328.cu(69): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

3 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122328.cu".
202307122328.cu

[INFO 2023-07-12 11:29:05 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:29:05 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:29:05 ]核函数数:1
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 17 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 2 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 2 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = malloc(sizeof(double)*N);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 8 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = malloc(sizeof(double)*N);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = malloc(sizeof(double)*10);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 2 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-12 11:29:05 ](Java2Cuda)耗时: 1 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[ERROR 2023-07-12 11:29:05 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122329.cu(67): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122329.cu(68): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122329.cu(69): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

3 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122329.cu".
202307122329.cu

[INFO 2023-07-12 11:30:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:30:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:30:29 ]核函数数:1
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 13 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 5 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 2 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = malloc(sizeof(double)*N);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = malloc(sizeof(double)*N);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = malloc(sizeof(double)*10);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 2 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 2 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-12 11:30:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[ERROR 2023-07-12 11:30:29 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122330.cu(67): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122330.cu(68): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307122330.cu(69): error: a value of type "void *" cannot be used to initialize an entity of type "double *"

3 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307122330.cu".
202307122330.cu

[INFO 2023-07-12 11:30:46 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:30:46 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:30:46 ]核函数数:1
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 3 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 14 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 2 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 1 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-12 11:30:46 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-12 11:31:31 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:31:31 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:31:31 ]核函数数:1
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 3 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 13 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 5 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 2 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:31:31 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:31:48 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:31:48 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:31:48 ]核函数数:1
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 11 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 5 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 2 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:31:48 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:32:25 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:32:25 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:32:25 ]核函数数:1
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 14 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 5 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d",argv[x]); ->             printf("%d",argv[x]);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:32:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:32:54 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:32:54 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:32:54 ]核函数数:1
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 11 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 3 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 6 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 2 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 2 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d",ICuda.atoi(argv[x])); ->             printf("%d",atoi(argv[x]));
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 3 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 4 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 1 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:32:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:33:17 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:33:17 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:33:17 ]核函数数:1
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 12 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 6 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 2 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d",ICuda.atoi(argv[x])); ->             printf("%d",atoi(argv[x]));
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:33:17 ](Java2Cuda)耗时: 2 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:33:38 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:33:38 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:33:38 ]核函数数:1
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 12 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 3 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 7 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 2 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n",ICuda.atoi(argv[x])); ->             printf("%d\n",atoi(argv[x]));
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 2 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:33:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:34:11 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:34:11 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:34:11 ]核函数数:1
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 14 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 7 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d\n",$a[x - 1]); ->             printf("%d\n",a[x - 1]);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:34:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:35:25 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:35:25 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:35:25 ]核函数数:1
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 13 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 6 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 2 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n",x); ->             printf("%d\n",x);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d\n",$a[x - 1]); ->             printf("%d\n",a[x - 1]);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:35:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:36:11 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:36:11 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:36:11 ]核函数数:1
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 9 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 9 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms             __shared__s_x[x] = $d_x[x]; ->             __shared__s_x[x] = d_x[x];
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d\n",x); ->             printf("%d\n",x);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 2 ms     } ->     }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n",$a[x - 1]); ->             printf("%d\n",a[x - 1]);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:36:11 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:36:38 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:36:38 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:36:38 ]核函数数:1
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 6 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 13 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 5 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n",x); ->             printf("%d\n",x);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n",$a[x - 1]); ->             printf("%d\n",a[x - 1]);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:36:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:37:24 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:37:24 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:37:24 ]核函数数:1
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 27 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 8 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 15 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 4 ms         { ->         {
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 3 ms             } ->             }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:37:24 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:37:55 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:37:55 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:37:55 ]核函数数:1
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 13 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N - 1;x ++) { ->         for (int x = 1 ;x < N - 1;x ++) {
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:37:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:38:14 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:38:14 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:38:14 ]核函数数:1
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 10 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 6 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 2 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         N = argc; ->         N = argc;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 2 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N + 1;x ++) { ->         for (int x = 1 ;x < N + 1;x ++) {
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:38:14 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:39:05 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:39:05 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:39:05 ]核函数数:1
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 15 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 2 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 9 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 2 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         for (int x = 1 ;x < N;x ++) { ->         for (int x = 1 ;x < N;x ++) {
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms             $a[x - 1] = ICuda.atoi(argv[x]); ->             a[x - 1] = atoi(argv[x]);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:39:05 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:39:43 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:39:43 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:39:43 ]核函数数:1
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 22 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 10 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 2 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 2 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 2 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 1 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:39:43 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:40:53 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:40:53 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:40:53 ]核函数数:1
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 22 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 3 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 2 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 12 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 2 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 2 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 2 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N + 1;x ++) { ->         for (int x = 0 ;x < N + 1;x ++) {
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 4 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:40:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:42:02 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:42:02 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:42:02 ]核函数数:1
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 13 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 2 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 2 ms             } ->             }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N + 1;x ++) { ->         for (int x = 0 ;x < N + 1;x ++) {
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n",argv[x]); ->             printf("%d\n",argv[x]);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:42:02 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:42:26 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:42:26 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:42:26 ]核函数数:1
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 3 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 18 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 11 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         System.out.printf("%d\n",__shared__s_x[n]); ->         printf("%d\n",__shared__s_x[n]);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N + 1;x ++) { ->         for (int x = 0 ;x < N + 1;x ++) {
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n", ICuda.atoi(argv[x])); ->             printf("%d\n", atoi(argv[x]));
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 2 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 1 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:42:26 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:42:58 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:42:58 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:42:58 ]核函数数:1
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 14 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 10 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 2 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 3 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 3 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N + 1;x ++) { ->         for (int x = 0 ;x < N + 1;x ++) {
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n", ICuda.atoi(argv[x])); ->             printf("%d\n", atoi(argv[x]));
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:42:58 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:43:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:43:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:43:29 ]核函数数:1
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 18 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 2 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N + 1;x ++) { ->         for (int x = 0 ;x < N + 1;x ++) {
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms             System.out.printf("%d\n", ICuda.atoi(argv[x + 1])); ->             printf("%d\n", atoi(argv[x + 1]));
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x]); ->             a[x] = atoi(argv[x]);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:43:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:43:52 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:43:52 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:43:52 ]核函数数:1
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 16 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 7 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 2 ms         { ->         {
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms             System.out.printf("%d\n", ICuda.atoi(argv[x + 1])); ->             printf("%d\n", atoi(argv[x + 1]));
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x + 1]); ->             a[x] = atoi(argv[x + 1]);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:43:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:45:27 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:45:27 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:45:27 ]核函数数:1
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 14 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 8 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 2 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 2 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms             $a[x] = ICuda.atoi(argv[x + 1]); ->             a[x] = atoi(argv[x + 1]);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 2 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %d \n",$b[0]); ->         printf("x sum:  %d \n",b[0]);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:45:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:46:36 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:46:36 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:46:36 ]核函数数:1
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 2 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 15 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 2 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 9 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 2 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 2 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x + 1]); ->             a[x] = atoi(argv[x + 1]);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time:%g ms .\n",elapsed_time); ->         printf("Time:%g ms .\n",elapsed_time);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         System.out.printf("x:%d \n",$b[0]); ->         printf("x:%d \n",b[0]);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:46:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-12 11:47:17 ]-------------------------新纪录--------------------------
[INFO 2023-07-12 11:47:17 ]使用版本:v1.2023.0621.10
[INFO 2023-07-12 11:47:17 ]核函数数:1
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 3 ms      int N = 1;//global ->      int N = 1;//global
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 21 ms int[] __device__d_z;//length:10 -> int d_z[10] =  {};//length:10
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 5 ms sum(int[] $d_x,int N)(GLOBAL) -> sum(int *d_x,int N)
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 12 ms         int[] __shared__s_x = {};//length:128 -> __shared__ int __shared__s_x[128];
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         int x = 0; ->         int x = 0;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         if(n < N) { ->         if(n < N) {
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms             __shared__s_x[n] = $d_x[n]; ->             __shared__s_x[n] = d_x[n];
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 2 ms         } ->         }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 3 ms             { ->             {
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 3 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 3 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 11 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         N = argc - 1; ->         N = argc - 1;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         int[] $a = (int[]) ICuda.malloc(ICuda.sizeof("int")*N); ->         int *a = (int*) malloc(sizeof(int)*N);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         int[] $b = ICuda.malloc(ICuda.sizeof("int")*10); ->         int *b = (int *) malloc(sizeof(int)*10);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms             $a[x] = ICuda.atoi(argv[x + 1]); ->             a[x] = atoi(argv[x + 1]);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         int[] $d_x = {}; ->         int *d_x;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("int")*N); ->         cudaMalloc((void **)&d_x,sizeof(int)*N);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("int")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(int)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 2 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,N); ->         sum<<<grid_size,block_size>>>(d_x,N);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time:%g ms\n",elapsed_time); ->         printf("Time:%g ms\n",elapsed_time);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("int")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(int)*10);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 3 ms         System.out.printf("x:%d \n",$b[0]); ->         printf("x:%d \n",b[0]);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         ICuda.free($a); ->         free(a);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 1 ms         ICuda.free($b); ->         free(b);
[INFO 2023-07-12 11:47:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x); ->         cudaFree(d_x);
[INFO 2023-07-16 10:35:59 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:35:59 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:35:59 ]核函数数:1
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 3 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         int[] $h = {}; ->         int *h;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:35:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:40:23 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:40:23 ]核函数数:1
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:40:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:41:34 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:41:34 ]核函数数:1
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 3 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 2 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:41:34 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:42:38 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:42:38 ]核函数数:1
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:42:38 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:47:20 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:47:20 ]核函数数:1
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:47:20 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:47:50 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:47:50 ]核函数数:1
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms     }//End ->     }//End
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:47:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:49:10 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:49:10 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:49:10 ]核函数数:1
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 14 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 5 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 2 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 3 ms         { ->         {
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 1 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-16 10:49:10 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-16 10:50:25 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:50:25 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:50:25 ]核函数数:1
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:50:25 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 10:54:18 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:54:18 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:54:18 ]核函数数:1
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 15 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 3 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 10 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 2 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 2 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 1 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-16 10:54:18 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-16 10:55:30 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:55:30 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:55:30 ]核函数数:1
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 2 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 22 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 2 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 11 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             { ->             {
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 3 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             } ->             }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-16 10:55:30 ](Java2Cuda)耗时: 1 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-16 10:56:09 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:56:09 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:56:09 ]核函数数:1
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms      final int N = 1000;//global ->      const int N = 1000;//global
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 15 ms double[] __device__d_z;//length:10 -> double d_z[10] =  {};//length:10
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms sum(double[] $d_x,double[] $d_y)(GLOBAL) -> sum(double *d_x,double *d_y)
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         final int tid = threadIdx.x; ->         const int tid = threadIdx.x;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         final int bid = blockIdx.x; ->         const int bid = blockIdx.x;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 9 ms         double[] __shared__s_x = {};//length:128 -> __shared__ double __shared__s_x[128];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_x2 = {};//length:128 -> __shared__ double __shared__s_x2[128];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         double[] __shared__s_y = {};//length:128 -> __shared__ double __shared__s_y[128];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         double[] __shared__s_xy = {};//length:128 -> __shared__ double __shared__s_xy[128];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         final int n = bid * blockDim.x + tid; ->         const int n = bid * blockDim.x + tid;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 2 ms         double x = 0.0; ->         double x = 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         double y = 0.0; ->         double y = 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         double x2 = 0.0; ->         double x2 = 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         double xy = 0.0; ->         double xy = 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         __shared__s_x[tid] = (n < N) ? $d_x[n] : 0.0; ->         __shared__s_x[tid] = (n < N) ? d_x[n] : 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0; ->         __shared__s_x2[tid] = (n < N) ? (__shared__s_x[tid] * __shared__s_x[tid]) : 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         __shared__s_y[tid] = (n < N) ? $d_y[n] : 0.0; ->         __shared__s_y[tid] = (n < N) ? d_y[n] : 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0; ->         __shared__s_xy[tid] = (n < N) ? __shared__s_x[tid] * __shared__s_y[tid] : 0.0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.__syncthreads(); ->         __syncthreads();
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) ->         for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1)
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             if (tid < offset) ->             if (tid < offset)
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             { ->             {
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms                 __shared__s_x[tid] += __shared__s_x[tid + offset]; ->                 __shared__s_x[tid] += __shared__s_x[tid + offset];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms                 __shared__s_y[tid] += __shared__s_y[tid + offset]; ->                 __shared__s_y[tid] += __shared__s_y[tid + offset];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms                 __shared__s_x2[tid] += __shared__s_x2[tid + offset]; ->                 __shared__s_x2[tid] += __shared__s_x2[tid + offset];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms                 __shared__s_xy[tid] += __shared__s_xy[tid + offset]; ->                 __shared__s_xy[tid] += __shared__s_xy[tid + offset];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             } ->             }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms             ICuda.__syncthreads(); ->             __syncthreads();
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 2 ms         y = __shared__s_y[tid]; ->         y = __shared__s_y[tid];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         x = __shared__s_x[tid]; ->         x = __shared__s_x[tid];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         x2 = __shared__s_x2[tid]; ->         x2 = __shared__s_x2[tid];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         xy = __shared__s_xy[tid]; ->         xy = __shared__s_xy[tid];
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         for (int offset = 16; offset > 0; offset >>= 1) ->         for (int offset = 16; offset > 0; offset >>= 1)
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         { ->         {
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             y += ICuda.__shfl_down_sync("0xffffffff",y, offset); ->             y += __shfl_down_sync(0xffffffff,y, offset);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             x += ICuda.__shfl_down_sync("0xffffffff",x, offset); ->             x += __shfl_down_sync(0xffffffff,x, offset);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             x2 += ICuda.__shfl_down_sync("0xffffffff",x2, offset); ->             x2 += __shfl_down_sync(0xffffffff,x2, offset);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms             xy += ICuda.__shfl_down_sync("0xffffffff",xy, offset); ->             xy += __shfl_down_sync(0xffffffff,xy, offset);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         if (tid == 0) ->         if (tid == 0)
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         { ->         {
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms             ICuda.atomicAdd(__device__d_z[0], x); ->             atomicAdd(&d_z[0], x);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[1], y); ->             atomicAdd(&d_z[1], y);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[2], x2); ->             atomicAdd(&d_z[2], x2);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             ICuda.atomicAdd(__device__d_z[3], xy); ->             atomicAdd(&d_z[3], xy);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         if(n == 0) { ->         if(n == 0) {
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             double fenzi = __device__d_z[3] - (__device__d_z[0] * __device__d_z[1] / N); ->             double fenzi = d_z[3] - (d_z[0] * d_z[1] / N);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             double fenmu = __device__d_z[2] - (__device__d_z[0] * __device__d_z[0] / N); ->             double fenmu = d_z[2] - (d_z[0] * d_z[0] / N);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             __device__d_z[4] = fenzi / fenmu; ->             d_z[4] = fenzi / fenmu;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             __device__d_z[5] = (__device__d_z[1] / N) - ((__device__d_z[0] / N) * __device__d_z[4]); ->             d_z[5] = (d_z[1] / N) - ((d_z[0] / N) * d_z[4]);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         double[] $a = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         double[] $a2 = ICuda.malloc(ICuda.sizeof("double")*N); ->         double *a2 = (double *) malloc(sizeof(double)*N);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         double[] $b = ICuda.malloc(ICuda.sizeof("double")*10); ->         double *b = (double *) malloc(sizeof(double)*10);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         for (int x = 0 ;x < N;x ++) { ->         for (int x = 0 ;x < N;x ++) {
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             $a[x] = 14.21412 + 1.1245 * x; ->             a[x] = 14.21412 + 1.1245 * x;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms             $a2[x] = 124.21452 + 123.0523 * x; ->             a2[x] = 124.21452 + 123.0523 * x;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         double[] $d_x = {}; ->         double *d_x;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         double[] $d_y = {}; ->         double *d_y;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("$d_x",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_x,sizeof(double)*N);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("$d_y",ICuda.sizeof("double")*N); ->         cudaMalloc((void **)&d_y,sizeof(double)*N);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("$d_x","$a",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x,a,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("$d_y","$a2",ICuda.sizeof("double")*N,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y,a2,sizeof(double)*N,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         cudaEvent_t start = new cudaEvent_t(); ->         cudaEvent_t start ;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         cudaEvent_t stop = new cudaEvent_t(); ->         cudaEvent_t stop ;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(start); ->         cudaEventCreate(&start);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventCreate(stop); ->         cudaEventCreate(&stop);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 2 ms         ICuda.cudaEventRecord(start); ->         cudaEventRecord(start);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         __global__sum($d_x,$d_y); ->         sum<<<grid_size,block_size>>>(d_x,d_y);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventRecord(stop); ->         cudaEventRecord(stop);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventSynchronize(stop); ->         cudaEventSynchronize(stop);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         float elapsed_time = 0; ->         float elapsed_time = 0;
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaEventElapsedTime(elapsed_time,start,stop); ->         cudaEventElapsedTime(&elapsed_time,start,stop);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         System.out.printf("Time = %g ms .\n",elapsed_time); ->         printf("Time = %g ms .\n",elapsed_time);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpyFromSymbol("b","d_z",ICuda.sizeof("double")*10); ->         cudaMemcpyFromSymbol(b,d_z,sizeof(double)*10);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         System.out.printf("x sum:  %f \n",$b[0]); ->         printf("x sum:  %f \n",b[0]);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         System.out.printf("y sum: %f \n",$b[1]); ->         printf("y sum: %f \n",b[1]);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 1 ms         System.out.printf("x2 sum: %f \n",$b[2]); ->         printf("x2 sum: %f \n",b[2]);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         System.out.printf("xy sum: %f \n",$b[3]); ->         printf("xy sum: %f \n",b[3]);
[INFO 2023-07-16 10:56:09 ](Java2Cuda)耗时: 0 ms         System.out.printf("Result: y =  %f * x + (%f) \n",$b[4],$b[5]); ->         printf("Result: y =  %f * x + (%f) \n",b[4],b[5]);
[INFO 2023-07-16 10:56:23 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 10:56:23 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 10:56:23 ]核函数数:1
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 2 ms     }//End ->     }//End
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 10:56:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:01:45 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:01:45 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:01:45 ]核函数数:1
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms     }//End ->     }//End
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 2 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:01:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:02:17 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:02:17 ]核函数数:1
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms     }//End ->     }//End
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:02:17 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:03:42 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:03:42 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:03:42 ]核函数数:1
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 2 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:03:42 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-16 11:03:42 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(11): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(32): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(34): warning #1444-D: function "cudaDeviceSynchronize"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_device_runtime_api.h(139): here was declared deprecated ("Use of cudaDeviceSynchronize from device code is deprecated. Moreover, such use will cause this module to fail to load on sm_90+ devices. If calls to cudaDeviceSynchronize from device code cannot be removed for older devices at this time, you may guard them with __CUDA_ARCH__ macros to remove them only for sm_90+ devices, making sure to generate code for compute_90 for the macros to take effect. Note that this mitigation will no longer work when support for cudaDeviceSynchronize from device code is eventually dropped for all devices. Disable this warning with -D__CDPRT_SUPPRESS_SYNC_DEPRECATION_WARNING.")

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(36): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(36): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(36): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(40): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162303.cu(4): warning #177-D: variable "N" was declared but never referenced

5 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162303.cu".
202307162303.cu

[INFO 2023-07-16 11:04:52 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:04:52 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:04:52 ]核函数数:1
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms } -> }
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:04:52 ](Java2Cuda)耗时: 3 ms  -> 
[ERROR 2023-07-16 11:04:52 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(14): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(35): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(37): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(37): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(37): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(41): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162304.cu(4): warning #177-D: variable "N" was declared but never referenced

5 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162304.cu".
202307162304.cu

[INFO 2023-07-16 11:05:36 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:05:36 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:05:36 ]核函数数:1
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n",threadIdxx,threadIdxy); ->         printf("(%d,%d)\n",threadIdx.x,threadIdx.y);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:05:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:12:45 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:12:45 ]核函数数:1
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 2 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:12:45 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-16 11:12:45 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162312.cu(8): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162312.cu".
202307162312.cu

[INFO 2023-07-16 11:13:49 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:13:49 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:13:49 ]核函数数:1
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,__device__add(threadIdx.x,threadIdx.y));
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> __device__add(int a,int b)
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:13:49 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-16 11:13:49 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162313.cu(8): error: identifier "__device__add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162313.cu".
202307162313.cu

[INFO 2023-07-16 11:14:51 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:14:51 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:14:51 ]核函数数:1
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:14:51 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-16 11:14:51 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162314.cu(8): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162314.cu".
202307162314.cu

[INFO 2023-07-16 11:19:07 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:19:07 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:19:07 ]核函数数:1
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 2 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:19:07 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-16 11:19:07 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162319.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162319.cu".
202307162319.cu

[INFO 2023-07-16 11:20:16 ]-------------------------新纪录--------------------------
[INFO 2023-07-16 11:20:16 ]使用版本:v1.2023.0621.10
[INFO 2023-07-16 11:20:16 ]核函数数:1
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 2 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 2 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-16 11:20:16 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-16 11:20:16 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307162320.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307162320.cu".
202307162320.cu

[INFO 2023-07-18 09:42:49 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:42:49 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:42:49 ]核函数数:1
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms } -> }
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:42:49 ](Java2Cuda)耗时: 2 ms  -> 
[ERROR 2023-07-18 09:42:49 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182142.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182142.cu".
202307182142.cu

[INFO 2023-07-18 09:43:12 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:43:12 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:43:12 ]核函数数:1
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 2 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 3 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 2 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:43:12 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 09:43:12 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182143.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182143.cu".
202307182143.cu

[INFO 2023-07-18 09:44:09 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:44:09 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:44:09 ]核函数数:1
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:44:09 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 09:44:09 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182144.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182144.cu".
202307182144.cu

[INFO 2023-07-18 09:49:13 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:49:13 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:49:13 ]核函数数:1
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms     public int __device__add(int a,int b) { ->     public int add(int a,int b) {
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:49:13 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 09:49:13 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(15): error: expected an expression

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(39): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(41): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(41): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(41): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(45): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(5): warning #177-D: variable "N" was declared but never referenced

6 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182149.cu".
202307182149.cu

[INFO 2023-07-18 09:49:40 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:49:40 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:49:40 ]核函数数:1
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         return 0; ->         return 0;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms     public int __device__add(int a,int b) { ->     public int add(int a,int b) {
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 2 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:49:40 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 09:49:40 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(17): error: expected a declaration

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(41): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(43): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(43): error: declaration is incompatible with "cudaError_t cudaMemcpy(void *, const void *, size_t, cudaMemcpyKind)"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_runtime_api.h(6266): here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(43): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(43): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(43): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(43): error: too many initializer values

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(46): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(46): error: declaration is incompatible with "void free(void *)"
C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_malloc.h(89): here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(47): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(47): error: declaration is incompatible with "cudaError_t cudaFree(void *)"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_device_runtime_api.h(159): here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(47): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(49): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(49): error: variable "cudaFree" has already been defined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(51): error: expected a declaration

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182149.cu(5): warning #177-D: variable "N" was declared but never referenced

16 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182149.cu".
202307182149.cu

[INFO 2023-07-18 09:50:41 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:50:41 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:50:41 ]核函数数:1
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 2 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 2 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:50:41 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 09:50:41 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182150.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182150.cu".
202307182150.cu

[INFO 2023-07-18 09:51:07 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 09:51:07 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 09:51:07 ]核函数数:1
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         return 0; ->         return 0;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms     } ->     }
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms     public int __device__add(int a,int b) { ->     public int add(int a,int b) {
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 09:51:07 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 09:51:07 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(18): error: expected a declaration

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(42): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(44): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(44): error: declaration is incompatible with "cudaError_t cudaMemcpy(void *, const void *, size_t, cudaMemcpyKind)"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_runtime_api.h(6266): here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(44): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(44): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(44): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(44): error: too many initializer values

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(47): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(47): error: declaration is incompatible with "void free(void *)"
C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_malloc.h(89): here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(48): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(48): error: declaration is incompatible with "cudaError_t cudaFree(void *)"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_device_runtime_api.h(159): here

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(48): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(50): error: this declaration has no storage class or type specifier

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(50): error: variable "cudaFree" has already been defined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(52): error: expected a declaration

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182151.cu(5): warning #177-D: variable "N" was declared but never referenced

16 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182151.cu".
202307182151.cu

[INFO 2023-07-18 10:00:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:00:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:00:29 ]核函数数:1
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 2 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 1 ms     } ->     }
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms     public int __device__add(int a,int b) { ->     __device__ int add(int a,int b) {
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:00:29 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:00:29 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182200.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182200.cu".
202307182200.cu

[INFO 2023-07-18 10:00:50 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:00:50 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:00:50 ]核函数数:1
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms     public int __device__add(int a,int b) { ->     __device__ int add(int a,int b) {
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:00:50 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-07-18 10:00:50 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182200.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182200.cu".
202307182200.cu

[INFO 2023-07-18 10:01:54 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:01:54 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:01:54 ]核函数数:1
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:01:54 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:01:54 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182201.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182201.cu".
202307182201.cu

[INFO 2023-07-18 10:02:53 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:02:53 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:02:53 ]核函数数:1
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 2 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:02:53 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:02:53 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182202.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182202.cu".
202307182202.cu

[INFO 2023-07-18 10:03:44 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:03:44 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:03:44 ]核函数数:1
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:03:44 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:03:44 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182203.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182203.cu".
202307182203.cu

[INFO 2023-07-18 10:04:10 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:04:10 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:04:10 ]核函数数:1
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:04:10 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-07-18 10:04:10 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182204.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182204.cu".
202307182204.cu

[INFO 2023-07-18 10:05:50 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:05:50 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:05:50 ]核函数数:999
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 3 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 2 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 2 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:05:50 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:05:50 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182205.cu(26): error: identifier "hello" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182205.cu".
202307182205.cu

[INFO 2023-07-18 10:06:19 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:06:19 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:06:19 ]核函数数:1
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 2 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:06:19 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:06:19 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182206.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182206.cu".
202307182206.cu

[INFO 2023-07-18 10:06:36 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:06:36 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:06:36 ]核函数数:1
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:06:36 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-07-18 10:06:36 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182206.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182206.cu".
202307182206.cu

[INFO 2023-07-18 10:10:55 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:10:55 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:10:55 ]核函数数:1
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 3 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:10:55 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:10:55 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182210.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182210.cu".
202307182210.cu

[INFO 2023-07-18 10:13:23 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:13:23 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:13:23 ]核函数数:1
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 2 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 2 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:13:23 ](Java2Cuda)耗时: 1 ms  -> 
[ERROR 2023-07-18 10:13:23 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182213.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182213.cu(15): error: identifier "a" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182213.cu(15): error: identifier "b" is undefined

3 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182213.cu".
202307182213.cu

[INFO 2023-07-18 10:17:27 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:17:27 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:17:27 ]核函数数:1
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:17:27 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:17:27 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(15): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(36): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(38): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(38): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(38): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(42): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182217.cu(5): warning #177-D: variable "N" was declared but never referenced

6 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182217.cu".
202307182217.cu

[INFO 2023-07-18 10:20:01 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:20:01 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:20:01 ]核函数数:1
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 2 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:20:01 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:20:01 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(15): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(36): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(38): warning #1444-D: function "cudaDeviceSynchronize"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_device_runtime_api.h(139): here was declared deprecated ("Use of cudaDeviceSynchronize from device code is deprecated. Moreover, such use will cause this module to fail to load on sm_90+ devices. If calls to cudaDeviceSynchronize from device code cannot be removed for older devices at this time, you may guard them with __CUDA_ARCH__ macros to remove them only for sm_90+ devices, making sure to generate code for compute_90 for the macros to take effect. Note that this mitigation will no longer work when support for cudaDeviceSynchronize from device code is eventually dropped for all devices. Disable this warning with -D__CDPRT_SUPPRESS_SYNC_DEPRECATION_WARNING.")

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(40): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(40): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(40): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(44): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182220.cu(5): warning #177-D: variable "N" was declared but never referenced

6 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182220.cu".
202307182220.cu

[INFO 2023-07-18 10:23:29 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:23:29 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:23:29 ]核函数数:1
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 2 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 2 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:23:29 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:23:29 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(9): error: identifier "add" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(15): error: expected a ";"

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(36): warning #12-D: parsing restarts here after previous syntax error

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(38): warning #1444-D: function "cudaDeviceSynchronize"
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\include\cuda_device_runtime_api.h(139): here was declared deprecated ("Use of cudaDeviceSynchronize from device code is deprecated. Moreover, such use will cause this module to fail to load on sm_90+ devices. If calls to cudaDeviceSynchronize from device code cannot be removed for older devices at this time, you may guard them with __CUDA_ARCH__ macros to remove them only for sm_90+ devices, making sure to generate code for compute_90 for the macros to take effect. Note that this mitigation will no longer work when support for cudaDeviceSynchronize from device code is eventually dropped for all devices. Disable this warning with -D__CDPRT_SUPPRESS_SYNC_DEPRECATION_WARNING.")

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(40): error: identifier "h_x" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(40): error: identifier "d_y1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(40): error: identifier "M" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(44): error: identifier "d_x1" is undefined

D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182223.cu(5): warning #177-D: variable "N" was declared but never referenced

6 errors detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182223.cu".
202307182223.cu

[INFO 2023-07-18 10:26:50 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:26:50 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:26:50 ]核函数数:1
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 2 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 2 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 2 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:26:50 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:26:50 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182226.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182226.cu".
202307182226.cu

[INFO 2023-07-18 10:31:53 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:31:53 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:31:53 ]核函数数:1
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 3 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 2 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 8 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 7 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:31:53 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:31:53 ]D:\idea_astralpathtalk\AstralPathCuda\AstralPathCuda\temp\202307182231.cu(9): error: identifier "add" is undefined

1 error detected in the compilation of "D:/idea_astralpathtalk/AstralPathCuda/AstralPathCuda//temp/202307182231.cu".
202307182231.cu

[INFO 2023-07-18 10:32:42 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:32:42 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:32:42 ]核函数数:1
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:32:42 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:33:22 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:33:22 ]核函数数:1
[INFO 2023-07-18 10:33:22 ]设备函数数:3
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d)\n = %d",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d)\n = %d",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:33:22 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:34:47 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:34:47 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:34:47 ]核函数数:1
[INFO 2023-07-18 10:34:47 ]设备函数数:3
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d) = %d \n",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d) = %d \n",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 2 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 2 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:34:47 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:36:15 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:36:15 ]核函数数:1
[INFO 2023-07-18 10:36:15 ]设备函数数:3
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 2 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d) = %d \n",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d) = %d \n",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         } ->         }
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 2 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 2 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:36:15 ](Java2Cuda)耗时: 0 ms  -> 
[ERROR 2023-07-18 10:36:15 ]nvcc fatal   : Unknown option '-oastralpathcuda.exe'

[INFO 2023-07-18 10:36:37 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:36:37 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:36:37 ]核函数数:1
[INFO 2023-07-18 10:36:37 ]设备函数数:3
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms __device__add()(GLOBAL) -> add()
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         return 0; ->         return 0;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms __device__add(int a,int b)(GLOBAL) -> add(int a,int b)
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms } -> }
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms __device__sum(int a,int b)(GLOBAL) -> sum(int a,int b)
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         return (a + b); ->         return (a + b);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b)(GLOBAL) -> hello(int *h,int *b)
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d) = %d \n",threadIdxx,threadIdxy,__device__add(threadIdxx,threadIdxy)); ->         printf("(%d,%d) = %d \n",threadIdx.x,threadIdx.y,add(threadIdx.x,threadIdx.y));
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 2 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         __global__hello($d_x1,$d_y1); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:36:37 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ]-------------------------新纪录--------------------------
[INFO 2023-07-18 10:40:59 ]使用版本:v1.2023.0621.10
[INFO 2023-07-18 10:40:59 ]核函数数:1
[INFO 2023-07-18 10:40:59 ]设备函数数:1
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 2 ms      final int N = 100;//global ->      const int N = 100;//global
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms __device__add(int[] $a,int[] $b,int[] $z)(GLOBAL) -> add(int *a,int *b,int *z)
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         $z[threadIdxx] = $a[threadIdxx]+ $b[threadIdxx]; ->         z[threadIdx.x] = a[threadIdx.x]+ b[threadIdx.x];
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 2 ms } -> }
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms hello(int[] $h,int[] $b,int[] $z)(GLOBAL) -> hello(int *h,int *b,int *z)
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 2 ms         int n = threadIdxx; ->         int n = threadIdx.x;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms         __device__add($h,$b,$z); ->         add(h,b,z);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms         System.out.printf("(%d,%d) = %d \n",threadIdxx,threadIdxy,$z[n]); ->         printf("(%d,%d) = %d \n",threadIdx.x,threadIdx.y,z[n]);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms         $b[n] = $h[n]; ->         b[n] = h[n];
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms } -> }
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         int M = ICuda.sizeof("int")*N; ->         int M = sizeof(int)*N;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         int[] $h_x = ICuda.malloc(M); ->         int *h_x = (int *) malloc(M);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         for (int x = 0;x < N;x ++) { ->         for (int x = 0;x < N;x ++) {
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms             $h_x[x] = 1; ->             h_x[x] = 1;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         } ->         }
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         int[] $d_x1 = {}; ->         int *d_x1;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         int[] $d_y1 = {}; ->         int *d_y1;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         int[] $d_y2 = {}; ->         int *d_y2;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMalloc("d_x1",M); ->         cudaMalloc((void **)&d_x1,M);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_x1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_x1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 8 ms         ICuda.cudaMalloc("d_y1",M); ->         cudaMalloc((void **)&d_y1,M);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("d_y1","h_x",M,cudaMemcpyHostToDevice); ->         cudaMemcpy(d_y1,h_x,M,cudaMemcpyHostToDevice);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms         ICuda.cudaMalloc("d_y2",M); ->         cudaMalloc((void **)&d_y2,M);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         final int block_size = 128; ->         const int block_size = 128;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         final int grid_size =  (N + block_size - 1) / block_size; ->         const int grid_size =  (N + block_size - 1) / block_size;
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         __global__hello($d_x1,$d_y1,$d_y2); ->         hello<<<grid_size,block_size>>>(d_x1,d_y1,d_y2);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 2 ms         ICuda.cudaDeviceSynchronize(); ->         cudaDeviceSynchronize();
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaMemcpy("h_x","d_y1",M,cudaMemcpyDeviceToHost); ->         cudaMemcpy(h_x,d_y1,M,cudaMemcpyDeviceToHost);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         ICuda.free($h_x); ->         free(h_x);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms         ICuda.cudaFree($d_x1); ->         cudaFree(d_x1);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 1 ms         ICuda.cudaFree($d_y1); ->         cudaFree(d_y1);
[INFO 2023-07-18 10:40:59 ](Java2Cuda)耗时: 0 ms  -> 
